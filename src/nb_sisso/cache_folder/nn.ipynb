{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 14:17:26,346 : numba=0.61.2, numpy=2.2.4\n",
      "2025-05-16 14:17:26,346 : OPT=_OptLevel(3), THREADING_LAYER=default\n",
      "2025-05-16 14:17:26,346 : USING_SVML=False, ENABLE_AVX=True, DISABLE_JIT=0\n",
      "2025-05-16 14:17:26,346 : max_op = 1  ,  date : 2025-05-16 14:17:26.346946\n",
      "2025-05-16 14:17:26,347 : use cores : 8\n",
      "2025-05-16 14:17:26,347 : making random_x\n",
      "2025-05-16 14:17:26,347 :    seed = 966, loop = 100000, upper = 0.5, lower = 1.5\n",
      "2025-05-16 14:17:26,690 : random_x corrcoef = 2.5018834937742225e-07\n",
      "2025-05-16 14:17:26,892 : make_before_similar_num_list\n",
      "2025-05-16 14:17:26,892 :    using Memory size =  194.5 MB\n",
      "2025-05-16 14:17:26,892 :    Memory size of numpy array = 0.0 M bytes +alpha (1data=1280 bytes, loop=2)\n",
      "2025-05-16 14:17:29,956 :    time : 0:00:03.063529\n",
      "2025-05-16 14:17:29,956 : make_unique_equations\n",
      "2025-05-16 14:17:29,957 :    n_op1 = 0, n_op2 = 0\n",
      "2025-05-16 14:17:31,518 :       make_unique_equations_thread\n",
      "2025-05-16 14:17:31,518 :          using Memory size =  244.8 MB\n",
      "2025-05-16 14:17:31,519 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=700 bytes, size_arr_for_mem=20)\n",
      "2025-05-16 14:17:34,530 :           0/20  (266.6 MB)  0:00:03.011313 : inf\n",
      "2025-05-16 14:17:37,552 :           0/20  (308.0 MB)  0:00:06.032704 : inf\n",
      "2025-05-16 14:17:40,648 :           0/20  (358.5 MB)  0:00:09.128763 : inf\n",
      "2025-05-16 14:17:43,651 :           0/20  (446.8 MB)  0:00:12.131629 : inf\n",
      "2025-05-16 14:17:46,652 :           0/20  (465.7 MB)  0:00:15.132543 : inf\n",
      "2025-05-16 14:17:47,214 :          time : 0:00:15.695136\n",
      "2025-05-16 14:17:47,214 :       dim_reduction\n",
      "2025-05-16 14:17:47,215 :          using Memory size =  467.8 MB\n",
      "2025-05-16 14:17:47,215 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=12)\n",
      "2025-05-16 14:17:48,168 :          time : 0:00:00.953193\n",
      "2025-05-16 14:17:48,169 :       make_check_exist_info\n",
      "2025-05-16 14:17:48,169 :          using Memory size =  480.5 MB\n",
      "2025-05-16 14:17:48,169 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=684 bytes, size_arr_for_mem=0)\n",
      "2025-05-16 14:17:49,525 :          time : 0:00:01.356845\n",
      "2025-05-16 14:17:49,526 :       dim_reduction_info\n",
      "2025-05-16 14:17:49,526 :          using Memory size =  490.7 MB\n",
      "2025-05-16 14:17:49,526 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=690 bytes, size_arr_for_mem=10)\n",
      "2025-05-16 14:17:50,523 :          time : 0:00:00.997907\n",
      "2025-05-16 14:17:50,524 :          using Memory size =  494.3 MB\n",
      "2025-05-16 14:17:50,525 :    check_exist_step1\n",
      "2025-05-16 14:17:50,525 :       using Memory size =  494.4 MB\n",
      "2025-05-16 14:17:50,525 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=2 bytes, size_arr_for_mem=0)\n",
      "2025-05-16 14:17:50,880 :       time : 0:00:00.354889\n",
      "2025-05-16 14:17:50,881 :    check_exist_step2\n",
      "2025-05-16 14:17:50,881 :       using Memory size =  495.0 MB\n",
      "2025-05-16 14:17:50,881 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=0)\n",
      "2025-05-16 14:17:51,520 :       time : 0:00:00.638532\n",
      "2025-05-16 14:17:51,521 :    check_exist_step3\n",
      "2025-05-16 14:17:51,521 :       using Memory size =  496.8 MB\n",
      "2025-05-16 14:17:51,521 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=5 bytes, size_arr_for_mem=0)\n",
      "2025-05-16 14:17:54,533 :       0/0  (556.9 MB)  0:00:03.011294 : inf\n",
      "2025-05-16 14:17:57,576 :       0/0  (566.5 MB)  0:00:06.054584 : inf\n",
      "2025-05-16 14:18:00,586 :       0/0  (660.8 MB)  0:00:09.064634 : inf\n",
      "2025-05-16 14:18:03,589 :       0/0  (661.4 MB)  0:00:12.067267 : inf\n",
      "2025-05-16 14:18:06,594 :       0/0  (665.2 MB)  0:00:15.072965 : inf\n",
      "2025-05-16 14:18:09,597 :       0/0  (670.2 MB)  0:00:18.075317 : inf\n",
      "2025-05-16 14:18:11,817 :       time : 0:00:20.296153\n",
      "2025-05-16 14:18:11,818 :    check_exist_step4\n",
      "2025-05-16 14:18:11,818 :       using Memory size =  681.7 MB\n",
      "2025-05-16 14:18:11,818 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=24 bytes, size_arr_for_mem=0)\n",
      "2025-05-16 14:18:13,481 :       time : 0:00:01.662331\n",
      "2025-05-16 14:18:13,483 :    tot             , [2, 10, 80, 911, 13471, 201551, 5561165] -> [2, 10, 80, 911, 13471, 201551, 5561165]\n",
      "2025-05-16 14:18:13,635 : need calc  6:4\n",
      "2025-05-16 14:18:13,635 :    time : 0:00:43.678726\n",
      "2025-05-16 14:18:13,635 : END\n",
      "2025-05-16 14:18:13,636 : total time : 0:00:47.288856\n",
      "2025-05-16 14:18:13,636 : numba=0.61.2, numpy=2.2.4\n",
      "2025-05-16 14:18:13,636 : OPT=_OptLevel(3), THREADING_LAYER=default\n",
      "2025-05-16 14:18:13,637 : USING_SVML=False, ENABLE_AVX=True, DISABLE_JIT=0\n",
      "2025-05-16 14:18:13,637 : max_op = 2  ,  date : 2025-05-16 14:18:13.637244\n",
      "2025-05-16 14:18:13,637 : use cores : 8\n",
      "2025-05-16 14:18:13,637 : making random_x\n",
      "2025-05-16 14:18:13,637 :    seed = 966, loop = 100000, upper = 0.5, lower = 1.5\n",
      "2025-05-16 14:18:13,701 : random_x corrcoef = 0.005378091523886421\n",
      "2025-05-16 14:18:13,781 : make_before_similar_num_list\n",
      "2025-05-16 14:18:13,782 :    using Memory size =  682.9 MB\n",
      "2025-05-16 14:18:13,782 :    Memory size of numpy array = 0.0 M bytes +alpha (1data=1280 bytes, loop=12)\n",
      "2025-05-16 14:18:13,783 :    time : 0:00:00.000416\n",
      "2025-05-16 14:18:13,783 : make_unique_equations\n",
      "2025-05-16 14:18:13,783 :    n_op1 = 1, n_op2 = 0\n",
      "2025-05-16 14:18:13,784 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:13,784 :          using Memory size =  682.9 MB\n",
      "2025-05-16 14:18:13,784 :          Memory size of numpy array = 0.1 M bytes +alpha (1data=714 bytes, size_arr_for_mem=132)\n",
      "2025-05-16 14:18:13,787 :          time : 0:00:00.002043\n",
      "2025-05-16 14:18:13,787 :       dim_reduction\n",
      "2025-05-16 14:18:13,787 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,787 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=71)\n",
      "2025-05-16 14:18:13,788 :          time : 0:00:00.000410\n",
      "2025-05-16 14:18:13,788 :       make_check_exist_info\n",
      "2025-05-16 14:18:13,788 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,788 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=687 bytes, size_arr_for_mem=22)\n",
      "2025-05-16 14:18:13,792 :          time : 0:00:00.004141\n",
      "2025-05-16 14:18:13,792 :       dim_reduction_info\n",
      "2025-05-16 14:18:13,792 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,793 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=704 bytes, size_arr_for_mem=58)\n",
      "2025-05-16 14:18:13,797 :          time : 0:00:00.004910\n",
      "2025-05-16 14:18:13,797 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,798 :    n_op1 = 0, n_op2 = 1\n",
      "2025-05-16 14:18:13,798 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:13,799 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,799 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=714 bytes, size_arr_for_mem=33)\n",
      "2025-05-16 14:18:13,801 :          time : 0:00:00.001726\n",
      "2025-05-16 14:18:13,801 :       dim_reduction\n",
      "2025-05-16 14:18:13,801 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,801 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=14)\n",
      "2025-05-16 14:18:13,802 :          time : 0:00:00.000433\n",
      "2025-05-16 14:18:13,802 :       make_check_exist_info\n",
      "2025-05-16 14:18:13,802 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,802 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=687 bytes, size_arr_for_mem=4)\n",
      "2025-05-16 14:18:13,804 :          time : 0:00:00.002470\n",
      "2025-05-16 14:18:13,805 :       dim_reduction_info\n",
      "2025-05-16 14:18:13,805 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,805 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=704 bytes, size_arr_for_mem=14)\n",
      "2025-05-16 14:18:13,807 :          time : 0:00:00.002382\n",
      "2025-05-16 14:18:13,807 :          using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,807 :    check_exist_step1\n",
      "2025-05-16 14:18:13,807 :       using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,808 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=2 bytes, size_arr_for_mem=26)\n",
      "2025-05-16 14:18:13,808 :       time : 0:00:00.000287\n",
      "2025-05-16 14:18:13,808 :    check_exist_step2\n",
      "2025-05-16 14:18:13,808 :       using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,809 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=8)\n",
      "2025-05-16 14:18:13,810 :       time : 0:00:00.001179\n",
      "2025-05-16 14:18:13,810 :    check_exist_step3\n",
      "2025-05-16 14:18:13,810 :       using Memory size =  683.0 MB\n",
      "2025-05-16 14:18:13,811 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=13 bytes, size_arr_for_mem=8)\n",
      "2025-05-16 14:18:13,812 :       time : 0:00:00.001039\n",
      "2025-05-16 14:18:13,812 :    check_exist_step4\n",
      "2025-05-16 14:18:13,812 :       using Memory size =  683.1 MB\n",
      "2025-05-16 14:18:13,813 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=24 bytes, size_arr_for_mem=4)\n",
      "2025-05-16 14:18:13,814 :       time : 0:00:00.001259\n",
      "2025-05-16 14:18:13,815 :    tot             , [2, 10, 80, 911, 13471, 201551, 5561165] -> [2, 10, 80, 911, 13471, 201551, 5561165]\n",
      "2025-05-16 14:18:13,817 : need calc  51:29\n",
      "2025-05-16 14:18:13,818 :    time : 0:00:00.034497\n",
      "2025-05-16 14:18:13,818 : END\n",
      "2025-05-16 14:18:13,818 : total time : 0:00:00.180824\n",
      "2025-05-16 14:18:13,819 : numba=0.61.2, numpy=2.2.4\n",
      "2025-05-16 14:18:13,819 : OPT=_OptLevel(3), THREADING_LAYER=default\n",
      "2025-05-16 14:18:13,819 : USING_SVML=False, ENABLE_AVX=True, DISABLE_JIT=0\n",
      "2025-05-16 14:18:13,819 : max_op = 3  ,  date : 2025-05-16 14:18:13.819852\n",
      "2025-05-16 14:18:13,820 : use cores : 8\n",
      "2025-05-16 14:18:13,820 : making random_x\n",
      "2025-05-16 14:18:13,820 :    seed = 966, loop = 100000, upper = 0.5, lower = 1.5\n",
      "2025-05-16 14:18:13,915 : random_x corrcoef = 0.03314654533373948\n",
      "2025-05-16 14:18:13,916 : make_before_similar_num_list\n",
      "2025-05-16 14:18:13,916 :    using Memory size =  683.1 MB\n",
      "2025-05-16 14:18:13,917 :    Memory size of numpy array = 0.1 M bytes +alpha (1data=1280 bytes, loop=92)\n",
      "2025-05-16 14:18:13,917 :    time : 0:00:00.000516\n",
      "2025-05-16 14:18:13,918 : make_unique_equations\n",
      "2025-05-16 14:18:13,918 :    n_op1 = 2, n_op2 = 0\n",
      "2025-05-16 14:18:13,919 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:13,919 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,919 :          Memory size of numpy array = 0.9 M bytes +alpha (1data=734 bytes, size_arr_for_mem=1232)\n",
      "2025-05-16 14:18:13,925 :          time : 0:00:00.005752\n",
      "2025-05-16 14:18:13,925 :       dim_reduction\n",
      "2025-05-16 14:18:13,926 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,926 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=645)\n",
      "2025-05-16 14:18:13,927 :          time : 0:00:00.000660\n",
      "2025-05-16 14:18:13,927 :       make_check_exist_info\n",
      "2025-05-16 14:18:13,927 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,928 :          Memory size of numpy array = 0.1 M bytes +alpha (1data=690 bytes, size_arr_for_mem=258)\n",
      "2025-05-16 14:18:13,947 :          time : 0:00:00.019924\n",
      "2025-05-16 14:18:13,947 :       dim_reduction_info\n",
      "2025-05-16 14:18:13,947 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,947 :          Memory size of numpy array = 0.3 M bytes +alpha (1data=724 bytes, size_arr_for_mem=494)\n",
      "2025-05-16 14:18:13,965 :          time : 0:00:00.017971\n",
      "2025-05-16 14:18:13,965 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,966 :    n_op1 = 1, n_op2 = 1\n",
      "2025-05-16 14:18:13,966 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:13,967 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,967 :          Memory size of numpy array = 0.9 M bytes +alpha (1data=734 bytes, size_arr_for_mem=1204)\n",
      "2025-05-16 14:18:13,973 :          time : 0:00:00.005832\n",
      "2025-05-16 14:18:13,973 :       dim_reduction\n",
      "2025-05-16 14:18:13,974 :          using Memory size =  683.2 MB\n",
      "2025-05-16 14:18:13,974 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=118)\n",
      "2025-05-16 14:18:13,975 :          time : 0:00:00.000551\n",
      "2025-05-16 14:18:13,975 :       make_check_exist_info\n",
      "2025-05-16 14:18:13,975 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:13,975 :          Memory size of numpy array = 0.3 M bytes +alpha (1data=690 bytes, size_arr_for_mem=468)\n",
      "2025-05-16 14:18:13,995 :          time : 0:00:00.020835\n",
      "2025-05-16 14:18:13,996 :       dim_reduction_info\n",
      "2025-05-16 14:18:13,996 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:13,996 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=724 bytes, size_arr_for_mem=88)\n",
      "2025-05-16 14:18:14,015 :          time : 0:00:00.019681\n",
      "2025-05-16 14:18:14,016 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,016 :    n_op1 = 0, n_op2 = 2\n",
      "2025-05-16 14:18:14,017 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:14,017 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,018 :          Memory size of numpy array = 0.3 M bytes +alpha (1data=734 bytes, size_arr_for_mem=308)\n",
      "2025-05-16 14:18:14,022 :          time : 0:00:00.003289\n",
      "2025-05-16 14:18:14,022 :       dim_reduction\n",
      "2025-05-16 14:18:14,022 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,023 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=101)\n",
      "2025-05-16 14:18:14,023 :          time : 0:00:00.000383\n",
      "2025-05-16 14:18:14,023 :       make_check_exist_info\n",
      "2025-05-16 14:18:14,024 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,024 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=690 bytes, size_arr_for_mem=51)\n",
      "2025-05-16 14:18:14,032 :          time : 0:00:00.008484\n",
      "2025-05-16 14:18:14,032 :       dim_reduction_info\n",
      "2025-05-16 14:18:14,032 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,033 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=724 bytes, size_arr_for_mem=97)\n",
      "2025-05-16 14:18:14,040 :          time : 0:00:00.007988\n",
      "2025-05-16 14:18:14,040 :          using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,041 :    check_exist_step1\n",
      "2025-05-16 14:18:14,041 :       using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,041 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=2 bytes, size_arr_for_mem=777)\n",
      "2025-05-16 14:18:14,042 :       time : 0:00:00.000564\n",
      "2025-05-16 14:18:14,042 :    check_exist_step2\n",
      "2025-05-16 14:18:14,043 :       using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,043 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=344)\n",
      "2025-05-16 14:18:14,062 :       time : 0:00:00.019073\n",
      "2025-05-16 14:18:14,062 :    check_exist_step3\n",
      "2025-05-16 14:18:14,063 :       using Memory size =  683.3 MB\n",
      "2025-05-16 14:18:14,063 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=25 bytes, size_arr_for_mem=344)\n",
      "2025-05-16 14:18:14,066 :       time : 0:00:00.002620\n",
      "2025-05-16 14:18:14,066 :    check_exist_step4\n",
      "2025-05-16 14:18:14,067 :       using Memory size =  683.4 MB\n",
      "2025-05-16 14:18:14,067 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=24 bytes, size_arr_for_mem=109)\n",
      "2025-05-16 14:18:14,072 :       time : 0:00:00.005492\n",
      "2025-05-16 14:18:14,073 :    tot             , [2, 10, 80, 911, 13471, 201551, 5561165] -> [2, 10, 80, 911, 13471, 201551, 5561165]\n",
      "2025-05-16 14:18:14,076 : need calc  630:281\n",
      "2025-05-16 14:18:14,076 :    time : 0:00:00.158377\n",
      "2025-05-16 14:18:14,076 : END\n",
      "2025-05-16 14:18:14,077 : total time : 0:00:00.256840\n",
      "2025-05-16 14:18:14,077 : numba=0.61.2, numpy=2.2.4\n",
      "2025-05-16 14:18:14,077 : OPT=_OptLevel(3), THREADING_LAYER=default\n",
      "2025-05-16 14:18:14,077 : USING_SVML=False, ENABLE_AVX=True, DISABLE_JIT=0\n",
      "2025-05-16 14:18:14,077 : max_op = 4  ,  date : 2025-05-16 14:18:14.077959\n",
      "2025-05-16 14:18:14,078 : use cores : 8\n",
      "2025-05-16 14:18:14,078 : making random_x\n",
      "2025-05-16 14:18:14,078 :    seed = 966, loop = 100000, upper = 0.5, lower = 1.5\n",
      "2025-05-16 14:18:14,210 : random_x corrcoef = 0.07169294170342125\n",
      "2025-05-16 14:18:14,212 : make_before_similar_num_list\n",
      "2025-05-16 14:18:14,212 :    using Memory size =  683.4 MB\n",
      "2025-05-16 14:18:14,212 :    Memory size of numpy array = 1.2 M bytes +alpha (1data=1280 bytes, loop=1003)\n",
      "2025-05-16 14:18:14,215 :    time : 0:00:00.002478\n",
      "2025-05-16 14:18:14,215 : make_unique_equations\n",
      "2025-05-16 14:18:14,215 :    n_op1 = 3, n_op2 = 0\n",
      "2025-05-16 14:18:14,216 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:14,216 :          using Memory size =  683.4 MB\n",
      "2025-05-16 14:18:14,217 :          Memory size of numpy array = 12.5 M bytes +alpha (1data=760 bytes, size_arr_for_mem=16024)\n",
      "2025-05-16 14:18:14,301 :          time : 0:00:00.084162\n",
      "2025-05-16 14:18:14,301 :       dim_reduction\n",
      "2025-05-16 14:18:14,302 :          using Memory size =  693.6 MB\n",
      "2025-05-16 14:18:14,302 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=7092)\n",
      "2025-05-16 14:18:14,303 :          time : 0:00:00.001508\n",
      "2025-05-16 14:18:14,304 :       make_check_exist_info\n",
      "2025-05-16 14:18:14,304 :          using Memory size =  693.6 MB\n",
      "2025-05-16 14:18:14,304 :          Memory size of numpy array = 3.5 M bytes +alpha (1data=693 bytes, size_arr_for_mem=5084)\n",
      "2025-05-16 14:18:14,525 :          time : 0:00:00.221896\n",
      "2025-05-16 14:18:14,526 :       dim_reduction_info\n",
      "2025-05-16 14:18:14,526 :          using Memory size =  693.6 MB\n",
      "2025-05-16 14:18:14,526 :          Memory size of numpy array = 4.1 M bytes +alpha (1data=750 bytes, size_arr_for_mem=5505)\n",
      "2025-05-16 14:18:14,755 :          time : 0:00:00.229332\n",
      "2025-05-16 14:18:14,755 :          using Memory size =  693.6 MB\n",
      "2025-05-16 14:18:14,757 :    n_op1 = 2, n_op2 = 1\n",
      "2025-05-16 14:18:14,758 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:14,758 :          using Memory size =  693.6 MB\n",
      "2025-05-16 14:18:14,759 :          Memory size of numpy array = 11.2 M bytes +alpha (1data=760 bytes, size_arr_for_mem=13616)\n",
      "2025-05-16 14:18:14,833 :          time : 0:00:00.074696\n",
      "2025-05-16 14:18:14,834 :       dim_reduction\n",
      "2025-05-16 14:18:14,834 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:14,834 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=1192)\n",
      "2025-05-16 14:18:14,835 :          time : 0:00:00.000645\n",
      "2025-05-16 14:18:14,835 :       make_check_exist_info\n",
      "2025-05-16 14:18:14,836 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:14,836 :          Memory size of numpy array = 4.3 M bytes +alpha (1data=693 bytes, size_arr_for_mem=6240)\n",
      "2025-05-16 14:18:15,046 :          time : 0:00:00.210733\n",
      "2025-05-16 14:18:15,046 :       dim_reduction_info\n",
      "2025-05-16 14:18:15,047 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:15,047 :          Memory size of numpy array = 0.8 M bytes +alpha (1data=750 bytes, size_arr_for_mem=1093)\n",
      "2025-05-16 14:18:15,249 :          time : 0:00:00.203453\n",
      "2025-05-16 14:18:15,250 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:15,253 :    n_op1 = 1, n_op2 = 2\n",
      "2025-05-16 14:18:15,254 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:15,254 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:15,255 :          Memory size of numpy array = 2.7 M bytes +alpha (1data=760 bytes, size_arr_for_mem=3404)\n",
      "2025-05-16 14:18:15,275 :          time : 0:00:00.020657\n",
      "2025-05-16 14:18:15,276 :       dim_reduction\n",
      "2025-05-16 14:18:15,276 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,276 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=308)\n",
      "2025-05-16 14:18:15,277 :          time : 0:00:00.000465\n",
      "2025-05-16 14:18:15,277 :       make_check_exist_info\n",
      "2025-05-16 14:18:15,278 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,278 :          Memory size of numpy array = 0.9 M bytes +alpha (1data=693 bytes, size_arr_for_mem=1424)\n",
      "2025-05-16 14:18:15,325 :          time : 0:00:00.047361\n",
      "2025-05-16 14:18:15,325 :       dim_reduction_info\n",
      "2025-05-16 14:18:15,325 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,325 :          Memory size of numpy array = 0.2 M bytes +alpha (1data=750 bytes, size_arr_for_mem=304)\n",
      "2025-05-16 14:18:15,361 :          time : 0:00:00.036732\n",
      "2025-05-16 14:18:15,362 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,364 :    n_op1 = 0, n_op2 = 3\n",
      "2025-05-16 14:18:15,365 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:15,365 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,366 :          Memory size of numpy array = 4.7 M bytes +alpha (1data=760 bytes, size_arr_for_mem=4006)\n",
      "2025-05-16 14:18:15,396 :          time : 0:00:00.029943\n",
      "2025-05-16 14:18:15,396 :       dim_reduction\n",
      "2025-05-16 14:18:15,396 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,397 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=957)\n",
      "2025-05-16 14:18:15,398 :          time : 0:00:00.000603\n",
      "2025-05-16 14:18:15,398 :       make_check_exist_info\n",
      "2025-05-16 14:18:15,398 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,398 :          Memory size of numpy array = 0.8 M bytes +alpha (1data=693 bytes, size_arr_for_mem=1294)\n",
      "2025-05-16 14:18:15,487 :          time : 0:00:00.089278\n",
      "2025-05-16 14:18:15,487 :       dim_reduction_info\n",
      "2025-05-16 14:18:15,488 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,488 :          Memory size of numpy array = 0.6 M bytes +alpha (1data=750 bytes, size_arr_for_mem=894)\n",
      "2025-05-16 14:18:15,573 :          time : 0:00:00.086118\n",
      "2025-05-16 14:18:15,573 :          using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,576 :    check_exist_step1\n",
      "2025-05-16 14:18:15,577 :       using Memory size =  692.2 MB\n",
      "2025-05-16 14:18:15,577 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=2 bytes, size_arr_for_mem=14042)\n",
      "2025-05-16 14:18:15,591 :       time : 0:00:00.013477\n",
      "2025-05-16 14:18:15,593 :    check_exist_step2\n",
      "2025-05-16 14:18:15,593 :       using Memory size =  683.6 MB\n",
      "2025-05-16 14:18:15,593 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=9457)\n",
      "2025-05-16 14:18:15,987 :       time : 0:00:00.394084\n",
      "2025-05-16 14:18:15,988 :    check_exist_step3\n",
      "2025-05-16 14:18:15,988 :       using Memory size =  683.7 MB\n",
      "2025-05-16 14:18:15,988 :       Memory size of numpy array = 0.3 M bytes +alpha (1data=41 bytes, size_arr_for_mem=9457)\n",
      "2025-05-16 14:18:16,051 :       time : 0:00:00.062398\n",
      "2025-05-16 14:18:16,053 :    check_exist_step4\n",
      "2025-05-16 14:18:16,053 :       using Memory size =  683.7 MB\n",
      "2025-05-16 14:18:16,054 :       Memory size of numpy array = 0.0 M bytes +alpha (1data=24 bytes, size_arr_for_mem=2591)\n",
      "2025-05-16 14:18:16,180 :       time : 0:00:00.125973\n",
      "2025-05-16 14:18:16,182 :    tot             , [2, 10, 80, 911, 13471, 201551, 5561165] -> [2, 10, 80, 911, 13471, 201551, 5561165]\n",
      "2025-05-16 14:18:16,187 : need calc  10208:3263\n",
      "2025-05-16 14:18:16,188 :    time : 0:00:01.972451\n",
      "2025-05-16 14:18:16,188 : END\n",
      "2025-05-16 14:18:16,188 : total time : 0:00:02.110041\n",
      "2025-05-16 14:18:16,188 : numba=0.61.2, numpy=2.2.4\n",
      "2025-05-16 14:18:16,189 : OPT=_OptLevel(3), THREADING_LAYER=default\n",
      "2025-05-16 14:18:16,189 : USING_SVML=False, ENABLE_AVX=True, DISABLE_JIT=0\n",
      "2025-05-16 14:18:16,189 : max_op = 5  ,  date : 2025-05-16 14:18:16.189432\n",
      "2025-05-16 14:18:16,189 : use cores : 8\n",
      "2025-05-16 14:18:16,189 : making random_x\n",
      "2025-05-16 14:18:16,189 :    seed = 966, loop = 100000, upper = 0.5, lower = 1.5\n",
      "2025-05-16 14:18:16,367 : random_x corrcoef = 0.09536325761088349\n",
      "2025-05-16 14:18:16,368 : make_before_similar_num_list\n",
      "2025-05-16 14:18:16,369 :    using Memory size =  683.7 MB\n",
      "2025-05-16 14:18:16,369 :    Memory size of numpy array = 18.5 M bytes +alpha (1data=1280 bytes, loop=14474)\n",
      "2025-05-16 14:18:16,433 :    time : 0:00:00.064156\n",
      "2025-05-16 14:18:16,434 : make_unique_equations\n",
      "2025-05-16 14:18:16,434 :    n_op1 = 4, n_op2 = 0\n",
      "2025-05-16 14:18:16,436 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:16,437 :          using Memory size =  692.6 MB\n",
      "2025-05-16 14:18:16,437 :          Memory size of numpy array = 210.1 M bytes +alpha (1data=792 bytes, size_arr_for_mem=264200)\n",
      "2025-05-16 14:18:19,024 :          time : 0:00:02.587397\n",
      "2025-05-16 14:18:19,025 :       dim_reduction\n",
      "2025-05-16 14:18:19,025 :          using Memory size =  864.5 MB\n",
      "2025-05-16 14:18:19,026 :          Memory size of numpy array = 0.7 M bytes +alpha (1data=8 bytes, size_arr_for_mem=96140)\n",
      "2025-05-16 14:18:19,047 :          time : 0:00:00.021272\n",
      "2025-05-16 14:18:19,048 :       make_check_exist_info\n",
      "2025-05-16 14:18:19,048 :          using Memory size =  864.5 MB\n",
      "2025-05-16 14:18:19,048 :          Memory size of numpy array = 76.2 M bytes +alpha (1data=696 bytes, size_arr_for_mem=109567)\n",
      "2025-05-16 14:18:22,593 :          time : 0:00:03.545692\n",
      "2025-05-16 14:18:22,593 :       dim_reduction_info\n",
      "2025-05-16 14:18:22,594 :          using Memory size =  931.3 MB\n",
      "2025-05-16 14:18:22,594 :          Memory size of numpy array = 58.4 M bytes +alpha (1data=782 bytes, size_arr_for_mem=74789)\n",
      "2025-05-16 14:18:26,138 :          time : 0:00:03.544957\n",
      "2025-05-16 14:18:26,138 :          using Memory size =  976.9 MB\n",
      "2025-05-16 14:18:26,190 :    n_op1 = 3, n_op2 = 1\n",
      "2025-05-16 14:18:26,192 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:26,193 :          using Memory size =  1137.0 MB\n",
      "2025-05-16 14:18:26,193 :          Memory size of numpy array = 166.1 M bytes +alpha (1data=792 bytes, size_arr_for_mem=208344)\n",
      "2025-05-16 14:18:28,222 :          time : 0:00:02.028983\n",
      "2025-05-16 14:18:28,223 :       dim_reduction\n",
      "2025-05-16 14:18:28,223 :          using Memory size =  956.4 MB\n",
      "2025-05-16 14:18:28,223 :          Memory size of numpy array = 0.1 M bytes +alpha (1data=8 bytes, size_arr_for_mem=14046)\n",
      "2025-05-16 14:18:28,226 :          time : 0:00:00.002860\n",
      "2025-05-16 14:18:28,227 :       make_check_exist_info\n",
      "2025-05-16 14:18:28,227 :          using Memory size =  956.7 MB\n",
      "2025-05-16 14:18:28,227 :          Memory size of numpy array = 79.6 M bytes +alpha (1data=696 bytes, size_arr_for_mem=114508)\n",
      "2025-05-16 14:18:31,045 :          time : 0:00:02.818947\n",
      "2025-05-16 14:18:31,046 :       dim_reduction_info\n",
      "2025-05-16 14:18:31,046 :          using Memory size =  961.4 MB\n",
      "2025-05-16 14:18:31,047 :          Memory size of numpy array = 10.1 M bytes +alpha (1data=782 bytes, size_arr_for_mem=12961)\n",
      "2025-05-16 14:18:33,778 :          time : 0:00:02.732760\n",
      "2025-05-16 14:18:33,779 :          using Memory size =  919.6 MB\n",
      "2025-05-16 14:18:33,828 :    n_op1 = 2, n_op2 = 2\n",
      "2025-05-16 14:18:33,830 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:33,831 :          using Memory size =  1017.9 MB\n",
      "2025-05-16 14:18:33,831 :          Memory size of numpy array = 158.1 M bytes +alpha (1data=792 bytes, size_arr_for_mem=176416)\n",
      "2025-05-16 14:18:35,776 :          time : 0:00:01.945198\n",
      "2025-05-16 14:18:35,777 :       dim_reduction\n",
      "2025-05-16 14:18:35,777 :          using Memory size =  985.8 MB\n",
      "2025-05-16 14:18:35,778 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=10396)\n",
      "2025-05-16 14:18:35,780 :          time : 0:00:00.002764\n",
      "2025-05-16 14:18:35,781 :       make_check_exist_info\n",
      "2025-05-16 14:18:35,781 :          using Memory size =  986.0 MB\n",
      "2025-05-16 14:18:35,781 :          Memory size of numpy array = 61.0 M bytes +alpha (1data=696 bytes, size_arr_for_mem=87724)\n",
      "2025-05-16 14:18:38,459 :          time : 0:00:02.678218\n",
      "2025-05-16 14:18:38,459 :       dim_reduction_info\n",
      "2025-05-16 14:18:38,459 :          using Memory size =  969.6 MB\n",
      "2025-05-16 14:18:38,460 :          Memory size of numpy array = 5.4 M bytes +alpha (1data=782 bytes, size_arr_for_mem=6974)\n",
      "2025-05-16 14:18:41,050 :          time : 0:00:02.591457\n",
      "2025-05-16 14:18:41,051 :          using Memory size =  969.6 MB\n",
      "2025-05-16 14:18:41,110 :    n_op1 = 1, n_op2 = 3\n",
      "2025-05-16 14:18:41,112 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:41,113 :          using Memory size =  1021.6 MB\n",
      "2025-05-16 14:18:41,113 :          Memory size of numpy array = 43.0 M bytes +alpha (1data=792 bytes, size_arr_for_mem=52086)\n",
      "2025-05-16 14:18:41,627 :          time : 0:00:00.513921\n",
      "2025-05-16 14:18:41,628 :       dim_reduction\n",
      "2025-05-16 14:18:41,628 :          using Memory size =  933.1 MB\n",
      "2025-05-16 14:18:41,628 :          Memory size of numpy array = 0.0 M bytes +alpha (1data=8 bytes, size_arr_for_mem=2991)\n",
      "2025-05-16 14:18:41,630 :          time : 0:00:00.001288\n",
      "2025-05-16 14:18:41,630 :       make_check_exist_info\n",
      "2025-05-16 14:18:41,630 :          using Memory size =  933.3 MB\n",
      "2025-05-16 14:18:41,631 :          Memory size of numpy array = 19.4 M bytes +alpha (1data=696 bytes, size_arr_for_mem=27909)\n",
      "2025-05-16 14:18:42,366 :          time : 0:00:00.736544\n",
      "2025-05-16 14:18:42,367 :       dim_reduction_info\n",
      "2025-05-16 14:18:42,367 :          using Memory size =  896.8 MB\n",
      "2025-05-16 14:18:42,367 :          Memory size of numpy array = 2.2 M bytes +alpha (1data=782 bytes, size_arr_for_mem=2925)\n",
      "2025-05-16 14:18:43,071 :          time : 0:00:00.705059\n",
      "2025-05-16 14:18:43,072 :          using Memory size =  897.1 MB\n",
      "2025-05-16 14:18:43,137 :    n_op1 = 0, n_op2 = 4\n",
      "2025-05-16 14:18:43,139 :       make_unique_equations_thread\n",
      "2025-05-16 14:18:43,140 :          using Memory size =  918.8 MB\n",
      "2025-05-16 14:18:43,140 :          Memory size of numpy array = 83.6 M bytes +alpha (1data=792 bytes, size_arr_for_mem=66050)\n",
      "2025-05-16 14:18:43,991 :          time : 0:00:00.851006\n",
      "2025-05-16 14:18:43,992 :       dim_reduction\n",
      "2025-05-16 14:18:43,992 :          using Memory size =  950.2 MB\n",
      "2025-05-16 14:18:43,992 :          Memory size of numpy array = 0.1 M bytes +alpha (1data=8 bytes, size_arr_for_mem=13461)\n",
      "2025-05-16 14:18:43,996 :          time : 0:00:00.002932\n",
      "2025-05-16 14:18:43,996 :       make_check_exist_info\n",
      "2025-05-16 14:18:43,996 :          using Memory size =  950.2 MB\n",
      "2025-05-16 14:18:43,996 :          Memory size of numpy array = 19.3 M bytes +alpha (1data=696 bytes, size_arr_for_mem=27829)\n",
      "2025-05-16 14:18:45,385 :          time : 0:00:01.389706\n",
      "2025-05-16 14:18:45,386 :       dim_reduction_info\n",
      "2025-05-16 14:18:45,386 :          using Memory size =  950.1 MB\n",
      "2025-05-16 14:18:45,386 :          Memory size of numpy array = 9.6 M bytes +alpha (1data=782 bytes, size_arr_for_mem=12310)\n",
      "2025-05-16 14:18:46,799 :          time : 0:00:01.413831\n",
      "2025-05-16 14:18:46,799 :          using Memory size =  950.1 MB\n",
      "2025-05-16 14:18:46,881 :    check_exist_step1\n",
      "2025-05-16 14:18:46,881 :       using Memory size =  979.0 MB\n",
      "2025-05-16 14:18:46,881 :       Memory size of numpy array = 0.7 M bytes +alpha (1data=2 bytes, size_arr_for_mem=367537)\n",
      "2025-05-16 14:18:49,891 :       282514/367537  (979.0 MB)  0:00:03.008824 : 0:00:00.905510\n",
      "2025-05-16 14:18:51,068 :       time : 0:00:04.186654\n",
      "2025-05-16 14:18:51,111 :    check_exist_step2\n",
      "2025-05-16 14:18:51,112 :       using Memory size =  926.8 MB\n",
      "2025-05-16 14:18:51,112 :       Memory size of numpy array = 2.2 M bytes +alpha (1data=8 bytes, size_arr_for_mem=286862)\n",
      "2025-05-16 14:18:54,116 :        94039/286861  (926.8 MB)  0:00:03.003350 : 0:00:06.158210\n",
      "2025-05-16 14:18:57,121 :       175158/286861  (926.8 MB)  0:00:06.008999 : 0:00:03.832101\n",
      "2025-05-16 14:19:00,127 :       275352/286861  (926.8 MB)  0:00:09.014533 : 0:00:00.376784\n",
      "2025-05-16 14:19:00,454 :       time : 0:00:09.342112\n",
      "2025-05-16 14:19:00,455 :    check_exist_step3\n",
      "2025-05-16 14:19:00,455 :       using Memory size =  926.8 MB\n",
      "2025-05-16 14:19:00,455 :       Memory size of numpy array = 17.4 M bytes +alpha (1data=61 bytes, size_arr_for_mem=286862)\n",
      "2025-05-16 14:19:03,461 :       33896/60873  (953.1 MB)  0:00:03.005034 : 0:00:02.391633\n",
      "2025-05-16 14:19:06,479 :       58970/60873  (953.5 MB)  0:00:06.023327 : 0:00:00.194377\n",
      "2025-05-16 14:19:07,508 :       time : 0:00:07.052116\n",
      "2025-05-16 14:19:07,553 :    check_exist_step4\n",
      "2025-05-16 14:19:07,553 :       using Memory size =  829.3 MB\n",
      "2025-05-16 14:19:07,554 :       Memory size of numpy array = 1.4 M bytes +alpha (1data=24 bytes, size_arr_for_mem=60873)\n",
      "2025-05-16 14:19:10,554 :       18462/60873  (829.3 MB)  0:00:03.000098 : 0:00:06.891840\n",
      "2025-05-16 14:19:13,558 :       60873/60873  (829.3 MB)  0:00:06.004195 : 0:00:00\n",
      "2025-05-16 14:19:14,830 :       time : 0:00:07.275954\n",
      "2025-05-16 14:19:14,852 :    tot             , [2, 10, 80, 911, 13471, 201551, 5561165] -> [2, 10, 80, 911, 13471, 251705, 5561165]\n",
      "2025-05-16 14:19:14,878 : need calc  201551:50154\n",
      "2025-05-16 14:19:14,886 :    time : 0:00:58.451973\n",
      "2025-05-16 14:19:14,886 : END\n",
      "2025-05-16 14:19:14,886 : total time : 0:00:58.697022\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from make_cache import main, decryption\n",
    "num_threads = 8\n",
    "max_n_plus = 5\n",
    "clear_mem = False\n",
    "seed = np.random.randint(10000)\n",
    "# seed = 2062\n",
    "# seed = 1986\n",
    "# seed = 9852\n",
    "for n_plus in range(1, max_n_plus + 1):\n",
    "    main(n_plus,num_threads,len_x=40, log_interval=3, seed=seed, clear_mem=clear_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6:4   \n",
    "51:29   \n",
    "630:281   \n",
    "10208:3263   \n",
    "201551:50154   \n",
    "[2, 10, 80, 911, 13471, 251705, 5561536]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"arr_len\", np.array([2],dtype=\"int64\"))\n",
    "#np.save(\"operator_0\",np.array([[1],[0]],dtype=\"int8\"))\n",
    "#np.savez(f\"check_change_x_tot_0\", np.full((2, 2, 2), -100, dtype=\"int8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13f241bd0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "base_T = 0\n",
    "def f2(mu):\n",
    "    f = lambda x: (np.exp(-(x - mu)**2/2)) / np.sqrt(2*np.pi)\n",
    "    return integrate.quad(f, mu - 5, 0)[0]\n",
    "arr_T = np.linspace(base_T - 5.0, base_T + 5.0, 1000)\n",
    "N = [f2(mu) for mu in arr_T]\n",
    "\n",
    "plt.plot(arr_T, np.cumsum(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4) 2 27.241269439861554\n",
      "(0, 1, 2, 4, 3) 2 10.724667872197235\n",
      "(0, 1, 3, 4, 2) 3 0.42739803452015795\n",
      "(0, 2, 1, 3, 4) 1 0.9193091512190226\n",
      "(0, 2, 1, 4, 3) 1 0.8854398582638005\n",
      "(0, 2, 3, 4, 1) 3 0.689877413659238\n",
      "(0, 3, 1, 4, 2) 1 0.6713242895130479\n",
      "(0, 3, 2, 4, 1) 2 13.58844200753505\n",
      "(1, 2, 3, 4, 0) 3 0.4697903603557153\n",
      "(1, 3, 2, 4, 0) 2 19.954345637740964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools as iter\n",
    "r_x = np.random.random(5)\n",
    "for i in iter.permutations([0,1,2,3,4]):\n",
    "    if i[0] < i[1] and i[2] < i[3] and i[0] < i[2] and i[1] < i[3]:\n",
    "        num = ((r_x[i[0]] * r_x[i[1]]) + (r_x[i[2]] * r_x[i[3]]))\n",
    "        num += ((r_x[i[1]] * r_x[i[3]]) + (r_x[i[2]] * r_x[i[4]]))\n",
    "        num /= r_x[i[2]]\n",
    "        print(i, i[2], num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [1, 0]]),\n",
       " {0: array([], shape=(1, 0, 2), dtype=int8),\n",
       "  1: array([], shape=(1, 0, 2), dtype=int8)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import njit, prange, set_num_threads, objmode, get_num_threads\n",
    "\n",
    "from utils_for_make_cache import *\n",
    "\n",
    "def sub_check_exist_step3_last(\n",
    "    max_op,\n",
    "    num_threads,\n",
    "    random_x,\n",
    "    check_exist_eq,\n",
    "    dict_mask_x,\n",
    "    indexes,\n",
    "):\n",
    "    # max_op = 7\n",
    "    print_counter = 0\n",
    "    lim_print_counter = 100000000\n",
    "    printed = False\n",
    "\n",
    "    int_nan = -100\n",
    "    arange = np.arange(indexes.shape[0])\n",
    "    equation = check_exist_eq[indexes[0]]\n",
    "    eq_x_max = np.max(equation)\n",
    "    mask_x = dict_mask_x[eq_x_max]\n",
    "    mat_use = np.empty((num_threads, indexes.shape[0], 3), dtype=\"int64\")\n",
    "    return_mat_use = np.full((indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "    norm_cache_for_mask_x = np.zeros((mask_x.shape[0], random_x.shape[1]), dtype=\"float64\")\n",
    "    TF_mask_x = np.ones((indexes.shape[0], mask_x.shape[0]), dtype=\"bool\")\n",
    "    norm_same_for_mask_x = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    dict_check_change_x = dict()\n",
    "    norm_n = 0\n",
    "    for k in range(mask_x.shape[0]):\n",
    "        similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "        norm_same = False\n",
    "        for l in range(norm_n):\n",
    "            if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                    norm_same = True\n",
    "                    break\n",
    "        if not norm_same:\n",
    "            norm_cache_for_mask_x[norm_n] = similar_num\n",
    "            norm_n += 1\n",
    "    norm_cache_for_mask_x = norm_cache_for_mask_x[:norm_n]\n",
    "    len_norm_cache_for_mask_x = norm_n\n",
    "\n",
    "    same_norm_num_index = np.empty((indexes.shape[0], mask_x.shape[0]), dtype=\"int64\")\n",
    "    patterns = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    use = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    n_max_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    n_min_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "\n",
    "    for j in range(indexes.shape[0]):\n",
    "        equation = check_exist_eq[indexes[j]]\n",
    "        before_check_change_x1 = np.array([[3, 4]])\n",
    "        changed_before_check_change_x2 = np.empty((0, 2), dtype=\"int64\")\n",
    "        len_before_check_change_x1 = count_True(before_check_change_x1[:, 0], 2, int_nan)  # 2 -> lambda x: x != border\n",
    "        len_before_check_change_x2 = count_True(\n",
    "            changed_before_check_change_x2[:, 0], 2, int_nan\n",
    "        )  # 2 -> lambda x: x != border\n",
    "        TF_mask_x[j] = True\n",
    "        for k in range(mask_x.shape[0]):\n",
    "            for l in range(len_before_check_change_x1):\n",
    "                if mask_x[k, before_check_change_x1[l, 0]] > mask_x[k, before_check_change_x1[l, 1]]:\n",
    "                    TF_mask_x[j, k] = False\n",
    "                    break\n",
    "            if TF_mask_x[j, k]:\n",
    "                for l in range(len_before_check_change_x2):\n",
    "                    if (\n",
    "                        mask_x[k, changed_before_check_change_x2[l, 0]]\n",
    "                        > mask_x[k, changed_before_check_change_x2[l, 1]]\n",
    "                    ):\n",
    "                        TF_mask_x[j, k] = False\n",
    "                        break\n",
    "            similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "            for l in range(len_norm_cache_for_mask_x):\n",
    "                if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                    if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                        norm_same_for_mask_x[k] = l\n",
    "                        break\n",
    "        same_norm_num_index[j] = norm_same_for_mask_x\n",
    "        arr_check_change_x = make_check_change_x(mask_x, norm_same_for_mask_x, TF_mask_x[j])[2]\n",
    "        dict_check_change_x[j] = arr_check_change_x\n",
    "        patterns[j] = arr_check_change_x.shape[0]\n",
    "    n_all_pattern = np.max(patterns)\n",
    "\n",
    "    mat_covered_num = np.zeros((indexes.shape[0], n_all_pattern, len_norm_cache_for_mask_x), dtype=\"bool\")\n",
    "    for j in range(indexes.shape[0]):\n",
    "        arr_check_change_x = dict_check_change_x[j]\n",
    "        for k in range(patterns[j]):\n",
    "            for l in range(mask_x.shape[0]):\n",
    "                if TF_mask_x[j, l]:\n",
    "                    check = True\n",
    "                    for m in range(arr_check_change_x.shape[1]):\n",
    "                        if int_nan == arr_check_change_x[k, m, 0]:\n",
    "                            break\n",
    "                        elif mask_x[l, arr_check_change_x[k, m, 0]] > mask_x[l, arr_check_change_x[k, m, 1]]:\n",
    "                            check = False\n",
    "                            break\n",
    "                    if check:\n",
    "                        if mat_covered_num[j, k, same_norm_num_index[j, l]]:\n",
    "                            print(\"ERROR : mat_covered_num\")\n",
    "                            print(check_exist_eq[indexes[j]])\n",
    "                            print(same_norm_num_index[j], TF_mask_x[j])\n",
    "                        else:  # if not mat_covered_num[j, k, same_num_index[j, l]]:\n",
    "                            mat_covered_num[j, k, same_norm_num_index[j, l]] = True\n",
    "        _arr = np.array([np.sum(mat_covered_num[j, k]) for k in range(patterns[j])])\n",
    "        n_max_mat_covered_num[j] = np.max(_arr)\n",
    "        n_min_mat_covered_num[j] = np.min(_arr)\n",
    "\n",
    "    # same eqs (1 op is safe)\n",
    "    same_eq_shape_S = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    c = 0\n",
    "    for j in range(indexes.shape[0]):\n",
    "        max_c = 0\n",
    "        for k in range(j):\n",
    "            if same_eq_shape_S[k] == max_c:\n",
    "                is_same = True\n",
    "                for l in range(check_exist_eq.shape[1]):\n",
    "                    if check_exist_eq[indexes[j], l] <= 0:\n",
    "                        if check_exist_eq[indexes[j], l] != check_exist_eq[indexes[k], l]:\n",
    "                            is_same = False\n",
    "                            break\n",
    "                    elif check_exist_eq[indexes[k], l] <= 0:\n",
    "                        is_same = False\n",
    "                        break\n",
    "                if is_same:\n",
    "                    same_eq_shape_S[j] = same_eq_shape_S[k]\n",
    "                    break\n",
    "                else:\n",
    "                    max_c += 1\n",
    "        if same_eq_shape_S[j] == int_nan:\n",
    "            same_eq_shape_S[j] = c\n",
    "            c += 1\n",
    "    len_n_same_eq_shape_S = c\n",
    "    same_eq_shape_L = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    c = 0\n",
    "    for j in range(indexes.shape[0]):\n",
    "        max_c = 0\n",
    "        for k in range(j):\n",
    "            if same_eq_shape_L[k] == max_c:\n",
    "                is_same = True\n",
    "                for l in range(check_exist_eq.shape[1]):\n",
    "                    if check_exist_eq[indexes[j], l] == 0:\n",
    "                        if check_exist_eq[indexes[k], l] != 0:\n",
    "                            is_same = False\n",
    "                            break\n",
    "                    elif check_exist_eq[indexes[k], l] == 0:\n",
    "                        is_same = False\n",
    "                        break\n",
    "                    elif check_exist_eq[indexes[j], l] in [-1, -2]:\n",
    "                        if not check_exist_eq[indexes[k], l] in [-1, -2]:\n",
    "                            is_same = False\n",
    "                            break\n",
    "                    elif check_exist_eq[indexes[k], l] in [-1, -2]:\n",
    "                        is_same = False\n",
    "                        break\n",
    "                    elif check_exist_eq[indexes[j], l] in [-3, -4]:\n",
    "                        if check_exist_eq[indexes[j], l] != check_exist_eq[indexes[k], l]:\n",
    "                            is_same = False\n",
    "                            break\n",
    "                    elif check_exist_eq[indexes[k], l] in [-3, -4]:\n",
    "                        is_same = False\n",
    "                        break\n",
    "                if is_same:\n",
    "                    same_eq_shape_L[j] = same_eq_shape_L[k]\n",
    "                    break\n",
    "                else:\n",
    "                    max_c += 1\n",
    "        if same_eq_shape_L[j] == int_nan:\n",
    "            same_eq_shape_L[j] = c\n",
    "            c += 1\n",
    "    len_n_same_eq_shape_L = c\n",
    "\n",
    "    arr_n_min = np.empty(len_n_same_eq_shape_L, dtype=\"int64\")\n",
    "    arr_n_max = np.empty(len_n_same_eq_shape_L, dtype=\"int64\")\n",
    "    for i in range(len_n_same_eq_shape_L):\n",
    "        selected_indexes = arange[same_eq_shape_L == i]\n",
    "        n_selected_indexes = selected_indexes.shape[0]\n",
    "        selected_n_max_mat_covered_num = np.sort(n_max_mat_covered_num[selected_indexes])[::-1]\n",
    "        selected_n_min_mat_covered_num = np.sort(n_min_mat_covered_num[selected_indexes])\n",
    "        sum_ = 0\n",
    "        arr_n_min[i] = n_selected_indexes + 1\n",
    "        for j in range(n_selected_indexes):\n",
    "            sum_ += selected_n_max_mat_covered_num[j]\n",
    "            if sum_ >= len_norm_cache_for_mask_x:\n",
    "                arr_n_min[i] = j + 1\n",
    "                break\n",
    "        sum_ = 0\n",
    "        arr_n_max[i] = n_selected_indexes\n",
    "        for j in range(n_selected_indexes):\n",
    "            sum_ += selected_n_min_mat_covered_num[j]\n",
    "            if sum_ == len_norm_cache_for_mask_x:\n",
    "                arr_n_max[i] = j + 1\n",
    "                break\n",
    "            elif sum_ > len_norm_cache_for_mask_x:\n",
    "                arr_n_max[i] = j\n",
    "                break\n",
    "\n",
    "    mat_use = np.full((len_n_same_eq_shape_L, indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "    arr_coverd = np.empty(len_norm_cache_for_mask_x, dtype=\"bool\")\n",
    "    for i in range(len_n_same_eq_shape_L):\n",
    "        base_selected_indexes = arange[same_eq_shape_L == i]\n",
    "        selected_indexes = np.empty_like(base_selected_indexes)\n",
    "        n_selected_indexes = 0\n",
    "        for j in range(np.max(same_eq_shape_S[base_selected_indexes]) + 1):\n",
    "            TF = same_eq_shape_S[base_selected_indexes] == j\n",
    "            selected_indexes[n_selected_indexes : n_selected_indexes + np.sum(TF)] = base_selected_indexes[TF]\n",
    "            n_selected_indexes += np.sum(TF)\n",
    "        len_mat_n_covered_num = 0\n",
    "        for j in selected_indexes:\n",
    "            len_mat_n_covered_num += patterns[j]\n",
    "        base_mat_n_covered_num = np.empty((len_mat_n_covered_num, 3), dtype=\"int64\")\n",
    "        c_mat_n_covered_num = 0\n",
    "        for j in selected_indexes:\n",
    "            for k in range(patterns[j]):\n",
    "                base_mat_n_covered_num[c_mat_n_covered_num, 0] = j\n",
    "                base_mat_n_covered_num[c_mat_n_covered_num, 1] = k\n",
    "                base_mat_n_covered_num[c_mat_n_covered_num, 2] = np.sum(mat_covered_num[j, k])\n",
    "                c_mat_n_covered_num += 1\n",
    "        mat_n_covered_num = np.empty((len_mat_n_covered_num, 3), dtype=\"int64\")\n",
    "        c_mat_n_covered_num = 0\n",
    "        for j in range(np.max(base_mat_n_covered_num[:, 2]), -1, -1):\n",
    "            same_n_covered_num_indexes = np.arange(len_mat_n_covered_num)[base_mat_n_covered_num[:, 2] == j]\n",
    "            mat_n_covered_num[c_mat_n_covered_num : c_mat_n_covered_num + same_n_covered_num_indexes.shape[0]] = (\n",
    "                base_mat_n_covered_num[same_n_covered_num_indexes]\n",
    "            )\n",
    "            c_mat_n_covered_num += same_n_covered_num_indexes.shape[0]\n",
    "        for start_index in range(len_mat_n_covered_num):\n",
    "            arr_coverd[:] = mat_covered_num[mat_n_covered_num[start_index, 0], mat_n_covered_num[start_index, 1]]\n",
    "            mat_use[i, 0, 0] = mat_n_covered_num[start_index, 0]\n",
    "            mat_use[i, 0, 1] = mat_n_covered_num[start_index, 1]\n",
    "            c_mat_use = 1\n",
    "            for j in range(start_index + 1, len_mat_n_covered_num):\n",
    "                if np.all(arr_coverd):\n",
    "                    break\n",
    "                if not mat_n_covered_num[j, 0] in mat_use[i, :c_mat_use, 0]:\n",
    "                    for k in range(len_norm_cache_for_mask_x):\n",
    "                        if arr_coverd[k]:\n",
    "                            if mat_covered_num[mat_n_covered_num[j, 0], mat_n_covered_num[j, 1], k]:\n",
    "                                break\n",
    "                    else:\n",
    "                        for k in range(len_norm_cache_for_mask_x):\n",
    "                            if not arr_coverd[k]:\n",
    "                                if mat_covered_num[mat_n_covered_num[j, 0], mat_n_covered_num[j, 1], k]:\n",
    "                                    arr_coverd[k] = True\n",
    "                        mat_use[i, c_mat_use, 0] = mat_n_covered_num[j, 0]\n",
    "                        mat_use[i, c_mat_use, 1] = mat_n_covered_num[j, 1]\n",
    "                        c_mat_use += 1\n",
    "            if not np.all(arr_coverd):\n",
    "                mat_use[i] = int_nan\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    if not np.any(mat_use[:, 0, 0] != int_nan):\n",
    "        mat_use = np.full((len_n_same_eq_shape_S, indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "        arr_coverd = np.empty(len_norm_cache_for_mask_x, dtype=\"bool\")\n",
    "        for i in range(len_n_same_eq_shape_S):\n",
    "            selected_indexes = arange[same_eq_shape_S == i]\n",
    "            len_mat_n_covered_num = 0\n",
    "            for j in selected_indexes:\n",
    "                len_mat_n_covered_num += patterns[j]\n",
    "            base_mat_n_covered_num = np.empty((len_mat_n_covered_num, 3), dtype=\"int64\")\n",
    "            c_mat_n_covered_num = 0\n",
    "            for j in selected_indexes:\n",
    "                for k in range(patterns[j]):\n",
    "                    base_mat_n_covered_num[c_mat_n_covered_num, 0] = j\n",
    "                    base_mat_n_covered_num[c_mat_n_covered_num, 1] = k\n",
    "                    base_mat_n_covered_num[c_mat_n_covered_num, 2] = np.sum(mat_covered_num[j, k])\n",
    "                    c_mat_n_covered_num += 1\n",
    "            mat_n_covered_num = np.empty((len_mat_n_covered_num, 3), dtype=\"int64\")\n",
    "            c_mat_n_covered_num = 0\n",
    "            for j in range(np.max(base_mat_n_covered_num[:, 2]), -1, -1):\n",
    "                same_n_covered_num_indexes = np.arange(len_mat_n_covered_num)[base_mat_n_covered_num[:, 2] == j]\n",
    "                mat_n_covered_num[c_mat_n_covered_num : c_mat_n_covered_num + same_n_covered_num_indexes.shape[0]] = (\n",
    "                    base_mat_n_covered_num[same_n_covered_num_indexes]\n",
    "                )\n",
    "                c_mat_n_covered_num += same_n_covered_num_indexes.shape[0]\n",
    "            for start_index in range(len_mat_n_covered_num):\n",
    "                arr_coverd[:] = mat_covered_num[mat_n_covered_num[start_index, 0], mat_n_covered_num[start_index, 1]]\n",
    "                mat_use[i, 0, 0] = mat_n_covered_num[start_index, 0]\n",
    "                mat_use[i, 0, 1] = mat_n_covered_num[start_index, 1]\n",
    "                c_mat_use = 1\n",
    "                for j in range(start_index + 1, len_mat_n_covered_num):\n",
    "                    if np.all(arr_coverd):\n",
    "                        break\n",
    "                    if not mat_n_covered_num[j, 0] in mat_use[i, :c_mat_use, 0]:\n",
    "                        for k in range(len_norm_cache_for_mask_x):\n",
    "                            if arr_coverd[k]:\n",
    "                                if mat_covered_num[mat_n_covered_num[j, 0], mat_n_covered_num[j, 1], k]:\n",
    "                                    break\n",
    "                        else:\n",
    "                            for k in range(len_norm_cache_for_mask_x):\n",
    "                                if not arr_coverd[k]:\n",
    "                                    if mat_covered_num[mat_n_covered_num[j, 0], mat_n_covered_num[j, 1], k]:\n",
    "                                        arr_coverd[k] = True\n",
    "                            mat_use[i, c_mat_use, 0] = mat_n_covered_num[j, 0]\n",
    "                            mat_use[i, c_mat_use, 1] = mat_n_covered_num[j, 1]\n",
    "                            c_mat_use += 1\n",
    "                if not np.all(arr_coverd):\n",
    "                    mat_use[i] = int_nan\n",
    "                else:\n",
    "                    break\n",
    "    if np.any(mat_use[:, 0, 0] != int_nan):\n",
    "        found_index = np.arange(mat_use.shape[0])[mat_use[:, 0, 0] != int_nan]\n",
    "        use_index = found_index[0]\n",
    "        n_use = np.sum(mat_use[use_index, :, 0] != int_nan)\n",
    "        for i in found_index[1:]:\n",
    "            if n_use > np.sum(mat_use[i, :, 0] != int_nan):\n",
    "                use_index = i\n",
    "                n_use = np.sum(mat_use[i, :, 0] != int_nan)\n",
    "        for i in range(n_use):\n",
    "            return_mat_use[i, 0] = mat_use[use_index, i, 0]\n",
    "            return_mat_use[i, 1] = mat_use[use_index, i, 1]\n",
    "        return return_mat_use, dict_check_change_x\n",
    "\n",
    "    print(\"not found aming\")\n",
    "    one_found = False\n",
    "    for i in range(2, indexes.shape[0] + 1):\n",
    "        for j in range(len_n_same_eq_shape_L):\n",
    "            if (arr_n_min[j] <= i) and (i <= arr_n_max[j]):\n",
    "                if not printed and (print_counter >= lim_print_counter):\n",
    "                    printed = True\n",
    "                    # \"\"\"  # print\n",
    "                    print(\"   arr_n_min : \", arr_n_min)\n",
    "                    print(\"   arr_n_max : \", arr_n_max)\n",
    "                    for k in range(indexes.shape[0]):\n",
    "                        print(k)\n",
    "                        print(\"   eq : \", check_exist_eq[indexes[k]])\n",
    "                        print(\"   same_eq_shape L, S : \", same_eq_shape_L[k], same_eq_shape_S[k])\n",
    "                        print(\"   n_max,min mat_covered_num : \", n_max_mat_covered_num[k], n_min_mat_covered_num[k])\n",
    "                        print(\"   mat_covered_num[0] : \", mat_covered_num[k, 0])\n",
    "                        print()\n",
    "                    print()\n",
    "                    # \"\"\"  # print\n",
    "                base_selected_indexes = arange[same_eq_shape_L == j]\n",
    "                selected_indexes = np.empty_like(base_selected_indexes)\n",
    "                n_selected_indexes = 0\n",
    "                for k in range(np.max(same_eq_shape_S[base_selected_indexes]) + 1):\n",
    "                    TF = same_eq_shape_S[base_selected_indexes] == k\n",
    "                    selected_indexes[n_selected_indexes : n_selected_indexes + np.sum(TF)] = base_selected_indexes[TF]\n",
    "                    n_selected_indexes += np.sum(TF)\n",
    "                # if n_selected_indexes != selected_indexes.shape[0]:\n",
    "                #    print(\"error : n_selected_indexes\")\n",
    "                use = np.arange(i)\n",
    "                use_pattern = np.empty(i, dtype=\"int64\")\n",
    "                tot_done_plus = True\n",
    "                while True:\n",
    "                    if np.sum(n_max_mat_covered_num[selected_indexes[use]]) >= len_norm_cache_for_mask_x:\n",
    "                        if len_norm_cache_for_mask_x >= np.sum(n_min_mat_covered_num[selected_indexes[use]]):\n",
    "                            use_pattern[:] = 0\n",
    "                            while True:\n",
    "                                print_counter += 1\n",
    "                                coverd = True\n",
    "                                for k in range(len_norm_cache_for_mask_x):\n",
    "                                    one_coverd = False\n",
    "                                    for l in range(i):\n",
    "                                        if mat_covered_num[selected_indexes[use[l]], use_pattern[l], k]:\n",
    "                                            if one_coverd:\n",
    "                                                coverd = False\n",
    "                                                break\n",
    "                                            else:\n",
    "                                                one_coverd = True\n",
    "                                    if not one_coverd:\n",
    "                                        coverd = False\n",
    "                                    if not coverd:\n",
    "                                        break\n",
    "                                if coverd:\n",
    "                                    for k in range(i):\n",
    "                                        mat_use[0, k, 0] = selected_indexes[use[k]]\n",
    "                                        mat_use[0, k, 1] = use_pattern[k]\n",
    "                                        mat_use[0, k, 2] = use[k]\n",
    "                                    mat_use[0, i:] = int_nan\n",
    "                                    one_found = True\n",
    "                                    break\n",
    "                                else:\n",
    "                                    done_plus_one = update_all_pattern(\n",
    "                                        use_pattern[:i], patterns[selected_indexes[use[:i]]]\n",
    "                                    )\n",
    "                                    if not done_plus_one:\n",
    "                                        break\n",
    "                    if one_found:\n",
    "                        break\n",
    "                    else:\n",
    "                        tot_done_plus = True\n",
    "                        for _ in range(num_threads):\n",
    "                            done_plus = update_combination(use[:i], n_selected_indexes)\n",
    "                            if not done_plus:\n",
    "                                tot_done_plus = False\n",
    "                                break\n",
    "                        if not tot_done_plus:\n",
    "                            break\n",
    "            if one_found:\n",
    "                break\n",
    "        if one_found:\n",
    "            break\n",
    "    if one_found:\n",
    "        n_use = np.sum(mat_use[0, :, 0] != int_nan)\n",
    "        for m in range(n_use):\n",
    "            return_mat_use[m, 0] = mat_use[0, m, 0]\n",
    "            return_mat_use[m, 1] = mat_use[0, m, 1]\n",
    "        return return_mat_use, dict_check_change_x\n",
    "\n",
    "    # round robin\n",
    "    # \"\"\" # print\n",
    "    print(\"find : round-robin\")\n",
    "    for j in range(indexes.shape[0]):\n",
    "        print(j)\n",
    "        print(\"   eq : \", check_exist_eq[indexes[j]])\n",
    "        print(\"   same_eq_shape L, S : \", same_eq_shape_L[j], same_eq_shape_S[j])\n",
    "        # print(\"   n_max,min mat_covered_num : \", n_max_mat_covered_num[j], n_min_mat_covered_num[j])\n",
    "        for k in range(patterns[j]):\n",
    "            print(\"   mat_covered_num[\", k, \"] : \", np.sum(mat_covered_num[j, k]), np.sort(same_norm_num_index[j][mat_covered_num[j, k]]))\n",
    "        print()\n",
    "\n",
    "    one_found = False\n",
    "    selected_indexes = np.empty(indexes.shape[0], dtype=\"int64\")\n",
    "    n_selected_indexes = 0\n",
    "    for i in range(len_n_same_eq_shape_L):\n",
    "        base_selected_indexes = arange[same_eq_shape_L == i]\n",
    "        for j in range(np.max(same_eq_shape_S[base_selected_indexes]) + 1):\n",
    "            TF = same_eq_shape_S[base_selected_indexes] == j\n",
    "            selected_indexes[n_selected_indexes : n_selected_indexes + np.sum(TF)] = base_selected_indexes[TF]\n",
    "            n_selected_indexes += np.sum(TF)\n",
    "    for i in range(2, indexes.shape[0] + 1):\n",
    "        if not printed and (print_counter >= lim_print_counter):\n",
    "            printed = True\n",
    "            # \"\"\"  # print\n",
    "            print(\"   arr_n_min : \", arr_n_min)\n",
    "            print(\"   arr_n_max : \", arr_n_max)\n",
    "            for j in range(indexes.shape[0]):\n",
    "                print(j)\n",
    "                print(\"   eq : \", check_exist_eq[indexes[j]])\n",
    "                print(\"   same_eq_shape L, S : \", same_eq_shape_L[j], same_eq_shape_S[j])\n",
    "                print(\"   n_max,min mat_covered_num : \", n_max_mat_covered_num[j], n_min_mat_covered_num[j])\n",
    "                print(\"   mat_covered_num[0] : \", mat_covered_num[j, 0])\n",
    "                print()\n",
    "            print()\n",
    "            # \"\"\"  # print\n",
    "        use = np.arange(i)\n",
    "        use_pattern = np.empty(i, dtype=\"int64\")\n",
    "        tot_done_plus = True\n",
    "        while True:\n",
    "            if np.sum(n_max_mat_covered_num[selected_indexes[use]]) >= len_norm_cache_for_mask_x:\n",
    "                if len_norm_cache_for_mask_x >= np.sum(n_min_mat_covered_num[selected_indexes[use]]):\n",
    "                    use_pattern[:] = 0\n",
    "                    while True:\n",
    "                        print_counter += 1\n",
    "                        coverd = True\n",
    "                        for k in range(len_norm_cache_for_mask_x):\n",
    "                            one_coverd = False\n",
    "                            for l in range(i):\n",
    "                                if mat_covered_num[selected_indexes[use[l]], use_pattern[l], k]:\n",
    "                                    if one_coverd:\n",
    "                                        coverd = False\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        one_coverd = True\n",
    "                            if not one_coverd:\n",
    "                                coverd = False\n",
    "                            if not coverd:\n",
    "                                break\n",
    "                        if coverd:\n",
    "                            for k in range(i):\n",
    "                                mat_use[0, k, 0] = selected_indexes[use[k]]\n",
    "                                mat_use[0, k, 1] = use_pattern[k]\n",
    "                                mat_use[0, k, 2] = use[k]\n",
    "                            mat_use[0, i:] = int_nan\n",
    "                            one_found = True\n",
    "                            break\n",
    "                        else:\n",
    "                            done_plus_one = update_all_pattern(\n",
    "                                use_pattern[:i], patterns[selected_indexes[use[:i]]]\n",
    "                            )\n",
    "                            if not done_plus_one:\n",
    "                                break\n",
    "            if one_found:\n",
    "                break\n",
    "            else:\n",
    "                tot_done_plus = True\n",
    "                for _ in range(num_threads):\n",
    "                    done_plus = update_combination(use[:i], n_selected_indexes)\n",
    "                    if not done_plus:\n",
    "                        tot_done_plus = False\n",
    "                        break\n",
    "                if not tot_done_plus:\n",
    "                    break\n",
    "        if one_found:\n",
    "            break\n",
    "    if one_found:\n",
    "        n_use = np.sum(mat_use[0, :, 0] != int_nan)\n",
    "        for m in range(n_use):\n",
    "            return_mat_use[m, 0] = mat_use[0, m, 0]\n",
    "            return_mat_use[m, 1] = mat_use[0, m, 1]\n",
    "        return return_mat_use, dict_check_change_x\n",
    "\n",
    "\n",
    "    print(\"\\nERROR : not seleced\")\n",
    "    for j in range(indexes.shape[0]):\n",
    "        print(\"   eq : \", check_exist_eq[indexes[j]])\n",
    "        before_check_change_x1 = np.array([[3, 4]])\n",
    "        len_before_check_change_x1 = count_True(before_check_change_x1[:, 0], 2, int_nan)  # 2 -> lambda x: x != border\n",
    "        print(\"   check1 : \", before_check_change_x1[:len_before_check_change_x1])\n",
    "        changed_before_check_change_x2 = np.empty((0, 2), dtype=\"int64\")\n",
    "        len_changed_before_check_change_x2 = count_True(\n",
    "            changed_before_check_change_x2[:, 0], 2, int_nan\n",
    "        )  # 2 -> lambda x: x != border\n",
    "        print(\"   check2 : \", changed_before_check_change_x2[:len_changed_before_check_change_x2])\n",
    "        print(\"   mat_check_change_x\")\n",
    "        l_mat_check_change_x = []\n",
    "        arr_check_change_x = dict_check_change_x[j]\n",
    "        for k in range(patterns[j]):\n",
    "            l_one_mat_check_change_x = []\n",
    "            for l in range(arr_check_change_x.shape[1]):\n",
    "                if arr_check_change_x[k, l, 0] != int_nan:\n",
    "                    l_one_mat_check_change_x.append(\n",
    "                        [int(arr_check_change_x[k, l, 0]), int(arr_check_change_x[k, l, 1])]\n",
    "                    )\n",
    "            l_mat_check_change_x.append(l_one_mat_check_change_x)\n",
    "        print(l_mat_check_change_x)\n",
    "        print(\"   same_num_index : \", same_norm_num_index[j])\n",
    "        print(\"   mat_covered_num : \", [mat_covered_num[j, k] for k in range(patterns[j])])\n",
    "    # \"\"\"  # print\n",
    "    return return_mat_use, dict_check_change_x\n",
    "\n",
    "max_op = 7\n",
    "num_threads = 3\n",
    "random_x = np.random.random((8,30))\n",
    "check_exist_eq = np.array([[1, 2, 3, 4, -2, -4, 5, -1, -4, 4, -4, 6, -2, 7, -3],\n",
    "                           [1, 2, 3, 4, -2, -4, 5, -2, -4, 3, -4, 6, -1, 7, -3]])\n",
    "dict_mask_x = make_dict_mask_x(max_op + 1)\n",
    "indexes = np.array([0, 1])\n",
    "\n",
    "sub_check_exist_step3_last(\n",
    "max_op,\n",
    "num_threads,\n",
    "random_x,\n",
    "check_exist_eq,\n",
    "dict_mask_x,\n",
    "indexes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[[[   1    5]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]]\n",
      "\n",
      " [[   3    5]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]]]\n",
      "test\n",
      "[[[   1    5]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]]\n",
      "\n",
      " [[   3    5]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]\n",
      "  [-100 -100]]]\n"
     ]
    }
   ],
   "source": [
    "from numba import njit, prange, set_num_threads, objmode, get_num_threads\n",
    "\n",
    "from utils_for_make_cache import *\n",
    "\n",
    "# @njit(error_model=\"numpy\")\n",
    "def sub_check_exist_step3_last(\n",
    "    max_op,\n",
    "    num_threads,\n",
    "    random_x,\n",
    "    check_exist_eq,\n",
    "    dict_mask_x,\n",
    "    indexes,\n",
    "):\n",
    "    # max_op = 7\n",
    "    print_counter = 0\n",
    "    lim_print_counter = 100000000\n",
    "    printed = False\n",
    "\n",
    "    int_nan = -100\n",
    "    arange = np.arange(indexes.shape[0])\n",
    "    equation = check_exist_eq[indexes[0]]\n",
    "    eq_x_max = np.max(equation)\n",
    "    mask_x = dict_mask_x[eq_x_max]\n",
    "    mat_use = np.empty((num_threads, indexes.shape[0], 3), dtype=\"int64\")\n",
    "    return_mat_use = np.full((indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "    norm_cache_for_mask_x = np.zeros((mask_x.shape[0], random_x.shape[1]), dtype=\"float64\")\n",
    "    TF_mask_x = np.ones((indexes.shape[0], mask_x.shape[0]), dtype=\"bool\")\n",
    "    norm_same_for_mask_x = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    dict_check_change_x = dict()\n",
    "    ssss = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    norm_n = 0\n",
    "    for k in range(mask_x.shape[0]):\n",
    "        similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "        norm_same = False\n",
    "        for l in range(norm_n):\n",
    "            if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                    norm_same = True\n",
    "                    break\n",
    "        if not norm_same:\n",
    "            norm_cache_for_mask_x[norm_n] = similar_num\n",
    "            ssss[norm_n] = k\n",
    "            norm_n += 1\n",
    "    norm_cache_for_mask_x = norm_cache_for_mask_x[:norm_n]\n",
    "    len_norm_cache_for_mask_x = norm_n\n",
    "\n",
    "    same_norm_num_index = np.empty((indexes.shape[0], mask_x.shape[0]), dtype=\"int64\")\n",
    "    patterns = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    use = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    n_max_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    n_min_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "\n",
    "    for j in range(indexes.shape[0]):\n",
    "        equation = check_exist_eq[indexes[j]]\n",
    "        before_check_change_x1 = np.array([[1, 3]])\n",
    "        changed_before_check_change_x2 = np.array([[5, 6]])\n",
    "        len_before_check_change_x1 = count_True(before_check_change_x1[:, 0], 2, int_nan)  # 2 -> lambda x: x != border\n",
    "        len_before_check_change_x2 = count_True(\n",
    "            changed_before_check_change_x2[:, 0], 2, int_nan\n",
    "        )  # 2 -> lambda x: x != border\n",
    "        TF_mask_x[j] = True\n",
    "        for k in range(mask_x.shape[0]):\n",
    "            for l in range(len_before_check_change_x1):\n",
    "                if mask_x[k, before_check_change_x1[l, 0]] > mask_x[k, before_check_change_x1[l, 1]]:\n",
    "                    TF_mask_x[j, k] = False\n",
    "                    break\n",
    "            if TF_mask_x[j, k]:\n",
    "                for l in range(len_before_check_change_x2):\n",
    "                    if (\n",
    "                        mask_x[k, changed_before_check_change_x2[l, 0]]\n",
    "                        > mask_x[k, changed_before_check_change_x2[l, 1]]\n",
    "                    ):\n",
    "                        TF_mask_x[j, k] = False\n",
    "                        break\n",
    "            similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "            for l in range(len_norm_cache_for_mask_x):\n",
    "                if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                    if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                        norm_same_for_mask_x[k] = l\n",
    "                        break\n",
    "        same_norm_num_index[j] = norm_same_for_mask_x\n",
    "        arr_check_change_x = make_check_change_x(j, mask_x, norm_same_for_mask_x, TF_mask_x[j])[2]\n",
    "        # if j == 2:\n",
    "        # print(\"norm_same_for_mask_x\")\n",
    "        # print(norm_same_for_mask_x)\n",
    "        print(\"test\")\n",
    "        #print(np.sort(norm_same_for_mask_x[(TF_mask_x[j] & (mask_x[:, 1] < mask_x[:, 6]))]))\n",
    "        print(arr_check_change_x)\n",
    "\n",
    "\n",
    "\n",
    "def make_check_change_x(number, mask, same_arr, TF_mask_x):\n",
    "    int_nan = -100\n",
    "    max_same_arr = np.max(same_arr)\n",
    "    unique = np.unique(same_arr[TF_mask_x])\n",
    "    all_covered = unique.shape[0] == max_same_arr + 1\n",
    "    if same_arr[TF_mask_x].shape[0] == unique.shape[0]:\n",
    "        return True, all_covered, np.empty((1, 0, 2), dtype=\"int8\")\n",
    "    len_arr = mask.shape[1]\n",
    "    TF = np.empty(((len_arr - 2) * (len_arr - 1), mask.shape[0]), dtype=\"bool\")\n",
    "    check_pattern = np.empty(((len_arr - 2) * (len_arr - 1), 2), dtype=\"int8\")\n",
    "    n = 0\n",
    "    saved_num = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    saved_num_for_TF_mask_x = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    for i in range(1, len_arr):\n",
    "        for j in range(1, len_arr):\n",
    "            if i != j:\n",
    "                check_pattern[n, 0] = i\n",
    "                check_pattern[n, 1] = j\n",
    "                saved_num[:] = False\n",
    "                for t in range(mask.shape[0]):\n",
    "                    TF[n, t] = mask[t, i] < mask[t, j]\n",
    "                    if TF[n, t]:\n",
    "                        saved_num[same_arr[t]] = True\n",
    "                if np.all(saved_num):\n",
    "                    n += 1\n",
    "    len_check_pattern = n\n",
    "    TF = TF[:len_check_pattern]\n",
    "    check_pattern = check_pattern[:len_check_pattern]\n",
    "\n",
    "    return_len = min(len_arr - 2, len_check_pattern)\n",
    "    use = np.empty((return_len), dtype=\"int64\")\n",
    "    save_use = np.empty((return_len), dtype=\"bool\")\n",
    "    return_dict = dict()\n",
    "    dict_saved_num = dict()\n",
    "    n = 0\n",
    "\n",
    "    for i in range(1, return_len + 1):\n",
    "        for j in range(i):\n",
    "            use[j] = j\n",
    "        while True:\n",
    "            saved_num[:] = False\n",
    "            saved_num_for_TF_mask_x[:] = False\n",
    "            check_TF_mask_x = True\n",
    "            for j in range(mask.shape[0]):\n",
    "                one_TF = True\n",
    "                for k in range(i):\n",
    "                    if not TF[use[k], j]:\n",
    "                        one_TF = False\n",
    "                        break\n",
    "                if one_TF:\n",
    "                    if TF_mask_x[j]:\n",
    "                        if saved_num_for_TF_mask_x[same_arr[j]]:\n",
    "                            check_TF_mask_x = False\n",
    "                            break\n",
    "                        else:\n",
    "                            saved_num_for_TF_mask_x[same_arr[j]] = True\n",
    "                    saved_num[same_arr[j]] = True\n",
    "            if check_TF_mask_x and np.all(saved_num):\n",
    "                if np.all(saved_num_for_TF_mask_x):\n",
    "                    return True, all_covered, np.expand_dims(check_pattern[use[:i]], axis=0)\n",
    "                elif np.any(saved_num_for_TF_mask_x):\n",
    "                    is_unique = True\n",
    "                    for j in range(n):\n",
    "                        one_dict_saved_num = dict_saved_num[j]\n",
    "                        sub_is_unique = False\n",
    "                        for k in range(saved_num.shape[0]):\n",
    "                            if one_dict_saved_num[k] != saved_num_for_TF_mask_x[k]:\n",
    "                                sub_is_unique = True\n",
    "                                break\n",
    "                        if not sub_is_unique:\n",
    "                            is_unique = False\n",
    "                            break\n",
    "                    if is_unique:\n",
    "                        save_use[:] = False\n",
    "                        for j in range(i):\n",
    "                            if not np.all(TF[use[j]][TF_mask_x]):\n",
    "                                save_use[j] = True\n",
    "                        return_dict[n] = check_pattern[use[save_use]].copy()\n",
    "                        dict_saved_num[n] = saved_num_for_TF_mask_x.copy()\n",
    "                        n += 1\n",
    "            done_plus = update_combination(use[:i], len_check_pattern)\n",
    "            if not done_plus:\n",
    "                break\n",
    "        if n != 0:\n",
    "            return_arr = np.full((n, return_len, 2), int_nan, dtype=\"int8\")\n",
    "            for j in range(n):\n",
    "                arr = return_dict[j]\n",
    "                return_arr[j, : arr.shape[0]] = arr\n",
    "            return True, False, return_arr\n",
    "    return False, False, np.empty((0, return_len, 2), dtype=\"int8\")\n",
    "\n",
    "\n",
    "max_op = 7\n",
    "num_threads = 3\n",
    "random_x = np.random.random((8, 30))\n",
    "check_exist_eq = np.array([[1, 2, -4, 3, 4, -4, -1, 5, 2, -4, 6, 4, -4, -1, -3],\n",
    "                           [1, 2, -4, 3, 4, -4, -1, 5, 4, -4, 6, 2, -4, -1, -3]])\n",
    "dict_mask_x = make_dict_mask_x(max_op + 1)\n",
    "indexes = np.array([0, 1])\n",
    "\n",
    "sub_check_exist_step3_last(\n",
    "max_op,\n",
    "num_threads,\n",
    "random_x,\n",
    "check_exist_eq,\n",
    "dict_mask_x,\n",
    "indexes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange, set_num_threads, objmode, get_num_threads\n",
    "\n",
    "from utils_for_make_cache import *\n",
    "\n",
    "# @njit(error_model=\"numpy\")\n",
    "def sub_check_exist_step3_last(\n",
    "    max_op,\n",
    "    num_threads,\n",
    "    random_x,\n",
    "    check_exist_eq,\n",
    "    dict_mask_x,\n",
    "    indexes,\n",
    "):\n",
    "    # max_op = 7\n",
    "    print_counter = 0\n",
    "    lim_print_counter = 100000000\n",
    "    printed = False\n",
    "\n",
    "    int_nan = -100\n",
    "    arange = np.arange(indexes.shape[0])\n",
    "    equation = check_exist_eq[indexes[0]]\n",
    "    eq_x_max = np.max(equation)\n",
    "    mask_x = dict_mask_x[eq_x_max]\n",
    "    mat_use = np.empty((num_threads, indexes.shape[0], 3), dtype=\"int64\")\n",
    "    return_mat_use = np.full((indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "    norm_cache_for_mask_x = np.zeros((mask_x.shape[0], random_x.shape[1]), dtype=\"float64\")\n",
    "    TF_mask_x = np.ones((indexes.shape[0], mask_x.shape[0]), dtype=\"bool\")\n",
    "    norm_same_for_mask_x = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    dict_check_change_x = dict()\n",
    "    ssss = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    norm_n = 0\n",
    "    for k in range(mask_x.shape[0]):\n",
    "        similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "        norm_same = False\n",
    "        for l in range(norm_n):\n",
    "            if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                    norm_same = True\n",
    "                    break\n",
    "        if not norm_same:\n",
    "            norm_cache_for_mask_x[norm_n] = similar_num\n",
    "            ssss[norm_n] = k\n",
    "            norm_n += 1\n",
    "    norm_cache_for_mask_x = norm_cache_for_mask_x[:norm_n]\n",
    "    len_norm_cache_for_mask_x = norm_n\n",
    "\n",
    "    same_norm_num_index = np.empty((indexes.shape[0], mask_x.shape[0]), dtype=\"int64\")\n",
    "    patterns = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    use = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    n_max_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    n_min_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "\n",
    "    for j in range(indexes.shape[0]):\n",
    "        equation = check_exist_eq[indexes[j]]\n",
    "        before_check_change_x1 = np.array([[1, 3]])\n",
    "        changed_before_check_change_x2 = np.array([[5, 6]])\n",
    "        len_before_check_change_x1 = count_True(before_check_change_x1[:, 0], 2, int_nan)  # 2 -> lambda x: x != border\n",
    "        len_before_check_change_x2 = count_True(\n",
    "            changed_before_check_change_x2[:, 0], 2, int_nan\n",
    "        )  # 2 -> lambda x: x != border\n",
    "        TF_mask_x[j] = True\n",
    "        for k in range(mask_x.shape[0]):\n",
    "            for l in range(len_before_check_change_x1):\n",
    "                if mask_x[k, before_check_change_x1[l, 0]] > mask_x[k, before_check_change_x1[l, 1]]:\n",
    "                    TF_mask_x[j, k] = False\n",
    "                    break\n",
    "            if TF_mask_x[j, k]:\n",
    "                for l in range(len_before_check_change_x2):\n",
    "                    if (\n",
    "                        mask_x[k, changed_before_check_change_x2[l, 0]]\n",
    "                        > mask_x[k, changed_before_check_change_x2[l, 1]]\n",
    "                    ):\n",
    "                        TF_mask_x[j, k] = False\n",
    "                        break\n",
    "            similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "            for l in range(len_norm_cache_for_mask_x):\n",
    "                if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                    if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                        norm_same_for_mask_x[k] = l\n",
    "                        break\n",
    "        same_norm_num_index[j] = norm_same_for_mask_x\n",
    "        arr_check_change_x = make_check_change_x(j, mask_x, norm_same_for_mask_x, TF_mask_x[j])[2]\n",
    "        # if j == 2:\n",
    "        # print(\"norm_same_for_mask_x\")\n",
    "        # print(norm_same_for_mask_x)\n",
    "        print(\"test\")\n",
    "        #print(np.sort(norm_same_for_mask_x[(TF_mask_x[j] & (mask_x[:, 1] < mask_x[:, 6]))]))\n",
    "        print(arr_check_change_x)\n",
    "\n",
    "\n",
    "\n",
    "def make_check_change_x(number, mask, same_arr, TF_mask_x):\n",
    "    int_nan = -100\n",
    "    max_same_arr = np.max(same_arr)\n",
    "    unique = np.unique(same_arr[TF_mask_x])\n",
    "    all_covered = unique.shape[0] == max_same_arr + 1\n",
    "    if same_arr[TF_mask_x].shape[0] == unique.shape[0]:\n",
    "        return True, all_covered, np.empty((1, 0, 2), dtype=\"int8\")\n",
    "    len_arr = mask.shape[1]\n",
    "    TF = np.empty(((len_arr - 2) * (len_arr - 1), mask.shape[0]), dtype=\"bool\")\n",
    "    check_pattern = np.empty(((len_arr - 2) * (len_arr - 1), 2), dtype=\"int8\")\n",
    "    n = 0\n",
    "    saved_num = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    saved_num_for_TF_mask_x = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    for i in range(1, len_arr):\n",
    "        for j in range(1, len_arr):\n",
    "            if i != j:\n",
    "                check_pattern[n, 0] = i\n",
    "                check_pattern[n, 1] = j\n",
    "                saved_num[:] = False\n",
    "                for t in range(mask.shape[0]):\n",
    "                    TF[n, t] = mask[t, i] < mask[t, j]\n",
    "                    if TF[n, t]:\n",
    "                        saved_num[same_arr[t]] = True\n",
    "                if np.all(saved_num):\n",
    "                    n += 1\n",
    "    len_check_pattern = n\n",
    "    TF = TF[:len_check_pattern]\n",
    "    check_pattern = check_pattern[:len_check_pattern]\n",
    "\n",
    "    return_len = min(len_arr - 2, len_check_pattern)\n",
    "    use = np.empty((return_len), dtype=\"int64\")\n",
    "    save_use = np.empty((return_len), dtype=\"bool\")\n",
    "    return_dict = dict()\n",
    "    dict_saved_num = dict()\n",
    "    n = 0\n",
    "\n",
    "    for i in range(1, return_len + 1):\n",
    "        for j in range(i):\n",
    "            use[j] = j\n",
    "        while True:\n",
    "            saved_num[:] = False\n",
    "            saved_num_for_TF_mask_x[:] = False\n",
    "            check_TF_mask_x = True\n",
    "            for j in range(mask.shape[0]):\n",
    "                one_TF = True\n",
    "                for k in range(i):\n",
    "                    if not TF[use[k], j]:\n",
    "                        one_TF = False\n",
    "                        break\n",
    "                if one_TF:\n",
    "                    if TF_mask_x[j]:\n",
    "                        if saved_num_for_TF_mask_x[same_arr[j]]:\n",
    "                            check_TF_mask_x = False\n",
    "                            break\n",
    "                        else:\n",
    "                            saved_num_for_TF_mask_x[same_arr[j]] = True\n",
    "                    saved_num[same_arr[j]] = True\n",
    "            if check_TF_mask_x and np.all(saved_num):\n",
    "                if np.all(saved_num_for_TF_mask_x):\n",
    "                    return True, all_covered, np.expand_dims(check_pattern[use[:i]], axis=0)\n",
    "                elif np.any(saved_num_for_TF_mask_x):\n",
    "                    is_unique = True\n",
    "                    for j in range(n):\n",
    "                        one_dict_saved_num = dict_saved_num[j]\n",
    "                        sub_is_unique = False\n",
    "                        for k in range(saved_num.shape[0]):\n",
    "                            if one_dict_saved_num[k] != saved_num_for_TF_mask_x[k]:\n",
    "                                sub_is_unique = True\n",
    "                                break\n",
    "                        if not sub_is_unique:\n",
    "                            is_unique = False\n",
    "                            break\n",
    "                    if is_unique:\n",
    "                        save_use[:] = False\n",
    "                        for j in range(i):\n",
    "                            if not np.all(TF[use[j]][TF_mask_x]):\n",
    "                                save_use[j] = True\n",
    "                        return_dict[n] = check_pattern[use[save_use]].copy()\n",
    "                        dict_saved_num[n] = saved_num_for_TF_mask_x.copy()\n",
    "                        n += 1\n",
    "            done_plus = update_combination(use[:i], len_check_pattern)\n",
    "            if not done_plus:\n",
    "                break\n",
    "        if n != 0:\n",
    "            return_arr = np.full((n, return_len, 2), int_nan, dtype=\"int8\")\n",
    "            for j in range(n):\n",
    "                arr = return_dict[j]\n",
    "                return_arr[j, : arr.shape[0]] = arr\n",
    "            return True, False, return_arr\n",
    "    return False, False, np.empty((0, return_len, 2), dtype=\"int8\")\n",
    "\n",
    "\n",
    "max_op = 7\n",
    "num_threads = 3\n",
    "random_x = np.random.random((8, 30))\n",
    "check_exist_eq = np.array([[1, 2, -4, 3, 4, -4, -1, 5, 2, -4, 6, 4, -4, -1, -3],\n",
    "                           [1, 2, -4, 3, 4, -4, -1, 5, 4, -4, 6, 2, -4, -1, -3]])\n",
    "dict_mask_x = make_dict_mask_x(max_op + 1)\n",
    "indexes = np.array([0, 1])\n",
    "\n",
    "sub_check_exist_step3_last(\n",
    "max_op,\n",
    "num_threads,\n",
    "random_x,\n",
    "check_exist_eq,\n",
    "dict_mask_x,\n",
    "indexes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3 -2 -4  1 -2  1  4  5 -2 -4 -1  6 -3]\n",
      "norm_same_for_mask_x\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  12  18  30  31  32  33\n",
      "   6  19  34  35  36  37   7  13  38  39  40  41  34  38  42  43  44  45\n",
      "  14  20  46  47  48  49   0  21  24  39  50  51   1  15  25  35  52  53\n",
      "  30  40  46  52  54  55   8  22  42  53  56  57   2  23  26  41  58  59\n",
      "   3   9  27  31  43  47  32  36  48  50  56  58  10  16  44  51  54  59\n",
      "   4  17  28  37  55  57   5  11  29  33  45  49  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  72  78  90  31  91  33  66  79  92  35  93  37\n",
      "  67  73  94  39  95  41  92  94  96  97  98  99  74  80 100  47 101  49\n",
      "  60  81  84  39 102  51  61  75  85  35 103  53  90  95 100 103 104 105\n",
      "  68  82  96  53 106  57  62  83  86  41 107  59  63  69  87  31  97  47\n",
      "  91  93 101 102 106 107  70  76  98  51 104  59  64  77  88  37 105  57\n",
      "  65  71  89  33  99  49 108 109 110 111 112 113 114 115 116  69 117  71\n",
      " 118 119 120  75 121  77 122 123 124  81 125  83 126 127 128 129 130 131\n",
      " 118 122 132   9 133  11 114 123 134  15 135  17 115 119 136  21 137  23\n",
      " 134 136 138  97 139  99 120 124 140  43 141  45 108  81 126  21 102  50\n",
      " 109  75 127  15 103  52 132 137 140 103 142 105 116 125 138  52 143  55\n",
      " 110  83 128  23 107  58 111  69 129   9  97  43 133 135 141 102 143 107\n",
      " 117 121 139  50 142  58 112  77 130  17 105  55 113  71 131  11  99  45\n",
      " 144 145 146 111 147 113 148 149 150  63 151  65 152 119 153  73 121  76\n",
      " 154 123 155  79 125  82 156 157 158 129 159 131 152 154 160   3 161   5\n",
      " 148 123 162  13 135  16 149 119 163  19 137  22 162 163 164  87 165  89\n",
      " 153 155 166  27 167  29 144  79 156  19  93  36 145  73 157  13  95  40\n",
      " 160 137 166  95 142 104 150 125 164  40 143  54 146  82 158  22 106  56\n",
      " 111  63 129   3  87  27 161 135 167  93 143 106 151 121 165  36 142  56\n",
      " 147  76 159  16 104  54 113  65 131   5  89  29 168 145 169 109 147 112\n",
      " 170 149 171  61 151  64 172 115 173  67 117  70 154 122 155  78 124  80\n",
      " 174 157 175 127 159 130 172 154 176   1 161   4 170 122 177   7 133  10\n",
      " 149 115 163  18 136  20 177 163 178  85 165  88 173 155 179  25 167  28\n",
      " 168  78 174  18  91  32 145  67 157   7  94  38 176 136 179  94 139  98\n",
      " 171 124 178  38 141  44 169  80 175  20 101  48 109  61 127   1  85  25\n",
      " 161 133 167  91 141 101 151 117 165  32 139  48 147  70 159  10  98  44\n",
      " 112  64 130   4  88  28 168 144 169 108 146 110 170 148 171  60 150  62\n",
      " 172 114 173  66 116  68 152 118 153  72 120  74 174 156 175 126 158 128\n",
      " 172 152 176   0 160   2 170 118 177   6 132   8 148 114 162  12 134  14\n",
      " 177 162 178  84 164  86 173 153 179  24 166  26 168  72 174  12  90  30\n",
      " 144  66 156   6  92  34 176 134 179  92 138  96 171 120 178  34 140  42\n",
      " 169  74 175  14 100  46 108  60 126   0  84  24 160 132 166  90 140 100\n",
      " 150 116 164  30 138  46 146  68 158   8  96  42 110  62 128   2  86  26]\n",
      "test\n",
      "0 (True, False, array([[[   1,    6],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   3,    5],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   5,    3],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n",
      "[ 1  2  3 -2 -4  1 -1  1  4  5 -2 -4 -1  6 -3]\n",
      "norm_same_for_mask_x\n",
      "[ 26  28  24  29  25  27  42  44  34  45  38  43  46  54  30  55  40  52\n",
      "  48  56  32  58  36  50   2   4   0   5   1   3  46  48  14  49  20  47\n",
      "  42  56   8  57  22  53  44  54  10  59  16  51   8  10   6  11   7   9\n",
      "  30  32  12  33  18  31  26  58   2  59  23  41  28  55   4  57  17  37\n",
      "  14  16  12  17  13  15  34  36   6  37  19  35  24  50   0  51  21  39\n",
      "  29  45   5  49  11  33  20  22  18  23  19  21  38  40   7  41  13  39\n",
      "  25  52   1  53  15  35  27  43   3  47   9  31  86  88  84  89  85  87\n",
      "  96  98  92  99  94  97 100 104  90 105  95 103 101 106  91 107  93 102\n",
      "  62  64  60  65  61  63 100 101  74  49  80  47  96 106  68  57  82  53\n",
      "  98 104  70  59  76  51  68  70  66  71  67  69  90  91  72  33  78  31\n",
      "  86 107  62  59  83  41  88 105  64  57  77  37  74  76  72  77  73  75\n",
      "  92  93  66  37  79  35  84 102  60  51  81  39  89  99  65  49  71  33\n",
      "  80  82  78  83  79  81  94  95  67  41  73  39  85 103  61  53  75  35\n",
      "  87  97  63  47  69  31 128 130 126 131 127 129 138 139 134  99 136  97\n",
      " 140 142 132 105 137 103 141 143 133 107 135 102 110 112 108 113 109 111\n",
      " 140 141 120  45 124  43 138 143 116  55 125  52 139 142 117  58 121  50\n",
      " 116 117 114  71 115  69 132 133 118  11 122   9 128 107 110  58  83  23\n",
      " 130 105 112  55  77  17 120 121 118  77 119  75 134 135 114  17 123  15\n",
      " 126 102 108  50  81  21 131  99 113  45  71  11 124 125 122  83 123  81\n",
      " 136 137 115  23 119  21 127 103 109  52  75  15 129  97 111  43  69   9\n",
      " 158 159 156 131 157 129 164 165 162  89 163  87 166 142 160 104 137  95\n",
      " 167 143 161 106 135  93 146 147 144 113 145 111 166 167 153  29 155  27\n",
      " 164 143 150  54 125  40 165 142 151  56 121  36 150 151 148  65 149  63\n",
      " 160 161 152   5 154   3 158 106 146  56  82  22 159 104 147  54  76  16\n",
      " 153 121 152  76 119  73 162 135 148  16 123  13 156  93 144  36  79  19\n",
      " 131  89 113  29  65   5 155 125 154  82 123  79 163 137 149  22 119  19\n",
      " 157  95 145  40  73  13 129  87 111  27  63   3 175 159 174 130 157 127\n",
      " 178 165 177  88 163  85 179 139 176  98 136  94 167 141 161 101 133  91\n",
      " 169 147 168 112 145 109 179 167 173  28 155  25 178 141 171  44 124  38\n",
      " 165 139 151  48 117  32 171 151 170  64 149  61 176 161 172   4 154   1\n",
      " 175 101 169  48  80  20 159  98 147  44  70  10 173 117 172  70 115  67\n",
      " 177 133 170  10 122   7 174  91 168  32  78  18 130  88 112  28  64   4\n",
      " 155 124 154  80 122  78 163 136 149  20 115  18 157  94 145  38  67   7\n",
      " 127  85 109  25  61   1 175 158 174 128 156 126 178 164 177  86 162  84\n",
      " 179 138 176  96 134  92 166 140 160 100 132  90 169 146 168 110 144 108\n",
      " 179 166 173  26 153  24 178 140 171  42 120  34 164 138 150  46 116  30\n",
      " 171 150 170  62 148  60 176 160 172   2 152   0 175 100 169  46  74  14\n",
      " 158  96 146  42  68   8 173 116 172  68 114  66 177 132 170   8 118   6\n",
      " 174  90 168  30  72  12 128  86 110  26  62   2 153 120 152  74 118  72\n",
      " 162 134 148  14 114  12 156  92 144  34  66   6 126  84 108  24  60   0]\n",
      "test\n",
      "1 (True, False, array([[[   1,    6],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   3,    5],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   5,    3],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n",
      "[ 1  2  3 -2 -4  1 -2  1  4  5 -2 -4 -2  6 -3]\n",
      "norm_same_for_mask_x\n",
      "[  2   4   0   5   1   3   8  10   6  11   7   9  14  16  12  17  13  15\n",
      "  20  22  18  23  19  21  26  28  24  29  25  27  30  32  12  33  18  31\n",
      "  34  36   6  37  19  35  38  40   7  41  13  39  42  44  34  45  38  43\n",
      "  46  48  14  49  20  47  24  50   0  51  21  39  25  52   1  53  15  35\n",
      "  46  54  30  55  40  52  42  56   8  57  22  53  26  58   2  59  23  41\n",
      "  27  43   3  47   9  31  48  56  32  58  36  50  44  54  10  59  16  51\n",
      "  28  55   4  57  17  37  29  45   5  49  11  33  62  64  60  65  61  63\n",
      "  68  70  66  71  67  69  74  76  72  77  73  75  80  82  78  83  79  81\n",
      "  86  88  84  89  85  87  90  91  72  33  78  31  92  93  66  37  79  35\n",
      "  94  95  67  41  73  39  96  98  92  99  94  97 100 101  74  49  80  47\n",
      "  84 102  60  51  81  39  85 103  61  53  75  35 100 104  90 105  95 103\n",
      "  96 106  68  57  82  53  86 107  62  59  83  41  87  97  63  47  69  31\n",
      " 101 106  91 107  93 102  98 104  70  59  76  51  88 105  64  57  77  37\n",
      "  89  99  65  49  71  33 110 112 108 113 109 111 116 117 114  71 115  69\n",
      " 120 121 118  77 119  75 124 125 122  83 123  81 128 130 126 131 127 129\n",
      " 132 133 118  11 122   9 134 135 114  17 123  15 136 137 115  23 119  21\n",
      " 138 139 134  99 136  97 140 141 120  45 124  43 126 102 108  50  81  21\n",
      " 127 103 109  52  75  15 140 142 132 105 137 103 138 143 116  55 125  52\n",
      " 128 107 110  58  83  23 129  97 111  43  69   9 141 143 133 107 135 102\n",
      " 139 142 117  58 121  50 130 105 112  55  77  17 131  99 113  45  71  11\n",
      " 146 147 144 113 145 111 150 151 148  65 149  63 153 121 152  76 119  73\n",
      " 155 125 154  82 123  79 158 159 156 131 157 129 160 161 152   5 154   3\n",
      " 162 135 148  16 123  13 163 137 149  22 119  19 164 165 162  89 163  87\n",
      " 166 167 153  29 155  27 156  93 144  36  79  19 157  95 145  40  73  13\n",
      " 166 142 160 104 137  95 164 143 150  54 125  40 158 106 146  56  82  22\n",
      " 129  87 111  27  63   3 167 143 161 106 135  93 165 142 151  56 121  36\n",
      " 159 104 147  54  76  16 131  89 113  29  65   5 169 147 168 112 145 109\n",
      " 171 151 170  64 149  61 173 117 172  70 115  67 155 124 154  80 122  78\n",
      " 175 159 174 130 157 127 176 161 172   4 154   1 177 133 170  10 122   7\n",
      " 163 136 149  20 115  18 178 165 177  88 163  85 179 167 173  28 155  25\n",
      " 174  91 168  32  78  18 157  94 145  38  67   7 179 139 176  98 136  94\n",
      " 178 141 171  44 124  38 175 101 169  48  80  20 127  85 109  25  61   1\n",
      " 167 141 161 101 133  91 165 139 151  48 117  32 159  98 147  44  70  10\n",
      " 130  88 112  28  64   4 169 146 168 110 144 108 171 150 170  62 148  60\n",
      " 173 116 172  68 114  66 153 120 152  74 118  72 175 158 174 128 156 126\n",
      " 176 160 172   2 152   0 177 132 170   8 118   6 162 134 148  14 114  12\n",
      " 178 164 177  86 162  84 179 166 173  26 153  24 174  90 168  30  72  12\n",
      " 156  92 144  34  66   6 179 138 176  96 134  92 178 140 171  42 120  34\n",
      " 175 100 169  46  74  14 126  84 108  24  60   0 166 140 160 100 132  90\n",
      " 164 138 150  46 116  30 158  96 146  42  68   8 128  86 110  26  62   2]\n",
      "test\n",
      "2 (True, False, array([[[   1,    6],\n",
      "        [   2,    5],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   3,    4],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   4,    3],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   1,    6],\n",
      "        [   5,    2],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n"
     ]
    }
   ],
   "source": [
    "from numba import njit, prange, set_num_threads, objmode, get_num_threads\n",
    "\n",
    "from utils_for_make_cache import *\n",
    "\n",
    "# @njit(error_model=\"numpy\")\n",
    "def sub_check_exist_step3_last(\n",
    "    max_op,\n",
    "    num_threads,\n",
    "    random_x,\n",
    "    check_exist_eq,\n",
    "    dict_mask_x,\n",
    "    indexes,\n",
    "    dict_before_check_change_x1,\n",
    "    dict_changed_before_check_change_x2,\n",
    "):\n",
    "    # max_op = 7\n",
    "    print_counter = 0\n",
    "    lim_print_counter = 100000000\n",
    "    printed = False\n",
    "\n",
    "    int_nan = -100\n",
    "    arange = np.arange(indexes.shape[0])\n",
    "    equation = check_exist_eq[indexes[0]]\n",
    "    eq_x_max = np.max(equation)\n",
    "    mask_x = dict_mask_x[eq_x_max]\n",
    "    mat_use = np.empty((num_threads, indexes.shape[0], 3), dtype=\"int64\")\n",
    "    return_mat_use = np.full((indexes.shape[0], 2), int_nan, dtype=\"int64\")\n",
    "    norm_cache_for_mask_x = np.zeros((mask_x.shape[0], random_x.shape[1]), dtype=\"float64\")\n",
    "    TF_mask_x = np.ones((indexes.shape[0], mask_x.shape[0]), dtype=\"bool\")\n",
    "    norm_same_for_mask_x = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    dict_check_change_x = dict()\n",
    "    ssss = np.zeros((mask_x.shape[0]), dtype=\"int64\")\n",
    "    norm_n = 0\n",
    "    for k in range(mask_x.shape[0]):\n",
    "        similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "        norm_same = False\n",
    "        for l in range(norm_n):\n",
    "            if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                    norm_same = True\n",
    "                    break\n",
    "        if not norm_same:\n",
    "            norm_cache_for_mask_x[norm_n] = similar_num\n",
    "            ssss[norm_n] = k\n",
    "            norm_n += 1\n",
    "    norm_cache_for_mask_x = norm_cache_for_mask_x[:norm_n]\n",
    "    len_norm_cache_for_mask_x = norm_n\n",
    "\n",
    "    same_norm_num_index = np.empty((indexes.shape[0], mask_x.shape[0]), dtype=\"int64\")\n",
    "    patterns = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    use = np.full((indexes.shape[0]), int_nan, dtype=\"int64\")\n",
    "    n_max_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "    n_min_mat_covered_num = np.empty((indexes.shape[0]), dtype=\"int64\")\n",
    "\n",
    "    for j in range(indexes.shape[0]):\n",
    "        equation = check_exist_eq[indexes[j]]\n",
    "        before_check_change_x1 = dict_before_check_change_x1[indexes[j]]\n",
    "        changed_before_check_change_x2 = dict_changed_before_check_change_x2[indexes[j]]\n",
    "        len_before_check_change_x1 = count_True(before_check_change_x1[:, 0], 2, int_nan)\n",
    "        len_before_check_change_x2 = count_True(\n",
    "            changed_before_check_change_x2[:, 0], 2, int_nan\n",
    "        )  # 2 -> lambda x: x != border\n",
    "        TF_mask_x[j] = True\n",
    "        for k in range(mask_x.shape[0]):\n",
    "            for l in range(len_before_check_change_x1):\n",
    "                if mask_x[k, before_check_change_x1[l, 0]] > mask_x[k, before_check_change_x1[l, 1]]:\n",
    "                    TF_mask_x[j, k] = False\n",
    "                    break\n",
    "            if TF_mask_x[j, k]:\n",
    "                for l in range(len_before_check_change_x2):\n",
    "                    if (\n",
    "                        mask_x[k, changed_before_check_change_x2[l, 0]]\n",
    "                        > mask_x[k, changed_before_check_change_x2[l, 1]]\n",
    "                    ):\n",
    "                        TF_mask_x[j, k] = False\n",
    "                        break\n",
    "            similar_num = nb_calc_RPN(random_x[mask_x[k]], equation)[0]\n",
    "            for l in range(len_norm_cache_for_mask_x):\n",
    "                if isclose(norm_cache_for_mask_x[l, 0], similar_num[0]):\n",
    "                    if isclose_arr(norm_cache_for_mask_x[l], similar_num):\n",
    "                        norm_same_for_mask_x[k] = l\n",
    "                        break\n",
    "        same_norm_num_index[j] = norm_same_for_mask_x\n",
    "        ans = make_check_change_x(mask_x, norm_same_for_mask_x, TF_mask_x[j])\n",
    "        arr_check_change_x = ans[2]\n",
    "        # if j == 2:\n",
    "        print(equation)\n",
    "        print(\"norm_same_for_mask_x\")\n",
    "        print(norm_same_for_mask_x)\n",
    "        print(\"test\")\n",
    "        #print(np.sort(norm_same_for_mask_x[(TF_mask_x[j] & (mask_x[:, 1] < mask_x[:, 6]))]))\n",
    "        print(j, ans)\n",
    "\n",
    "\n",
    "def make_check_change_x(mask, same_arr, TF_mask_x):\n",
    "    int_nan = -100\n",
    "    max_same_arr = np.max(same_arr)\n",
    "    unique = np.unique(same_arr[TF_mask_x])\n",
    "    all_covered = unique.shape[0] == max_same_arr + 1\n",
    "    # if same_arr[TF_mask_x].shape[0] == unique.shape[0]:\n",
    "    #     return True, all_covered, np.empty((1, 0, 2), dtype=\"int8\")\n",
    "    len_arr = mask.shape[1]\n",
    "    TF = np.empty(((len_arr - 2) * (len_arr - 1), mask.shape[0]), dtype=\"bool\")\n",
    "    check_pattern = np.empty(((len_arr - 2) * (len_arr - 1), 2), dtype=\"int8\")\n",
    "    n = 0\n",
    "    saved_num = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    saved_num_for_TF_mask_x = np.empty((max_same_arr + 1), dtype=\"bool\")\n",
    "    for i in range(1, len_arr):\n",
    "        for j in range(1, len_arr):\n",
    "            if i != j:\n",
    "                check_pattern[n, 0] = i\n",
    "                check_pattern[n, 1] = j\n",
    "                saved_num[:] = False\n",
    "                for t in range(mask.shape[0]):\n",
    "                    TF[n, t] = mask[t, i] < mask[t, j]\n",
    "                    if TF[n, t]:\n",
    "                        saved_num[same_arr[t]] = True\n",
    "                if np.all(saved_num):\n",
    "                    n += 1\n",
    "    len_check_pattern = n\n",
    "    TF = TF[:len_check_pattern]\n",
    "    check_pattern = check_pattern[:len_check_pattern]\n",
    "\n",
    "    return_len = min(len_arr - 2, len_check_pattern)\n",
    "    use = np.empty((return_len), dtype=\"int64\")\n",
    "    save_use = np.empty((return_len), dtype=\"bool\")\n",
    "    return_dict = dict()\n",
    "    dict_saved_num = dict()\n",
    "    n = 0\n",
    "\n",
    "    for i in range(1, return_len + 1):\n",
    "        for j in range(i):\n",
    "            use[j] = j\n",
    "        while True:\n",
    "            saved_num[:] = False\n",
    "            saved_num_for_TF_mask_x[:] = False\n",
    "            check_TF_mask_x = True\n",
    "            for j in range(mask.shape[0]):\n",
    "                one_TF = True\n",
    "                for k in range(i):\n",
    "                    if not TF[use[k], j]:\n",
    "                        one_TF = False\n",
    "                        break\n",
    "                if one_TF:\n",
    "                    if saved_num[same_arr[j]]:\n",
    "                        saved_num[same_arr[j]] = False\n",
    "                        break\n",
    "                    else:\n",
    "                        saved_num[same_arr[j]] = True\n",
    "                        if TF_mask_x[j]:\n",
    "                            saved_num_for_TF_mask_x[same_arr[j]] = True\n",
    "            if np.all(saved_num):\n",
    "                if np.all(saved_num_for_TF_mask_x):\n",
    "                    return True, all_covered, np.expand_dims(check_pattern[use[:i]], axis=0)\n",
    "                elif np.any(saved_num_for_TF_mask_x):\n",
    "                    is_unique = True\n",
    "                    for j in range(n):\n",
    "                        one_dict_saved_num = dict_saved_num[j]\n",
    "                        sub_is_unique = False\n",
    "                        for k in range(saved_num_for_TF_mask_x.shape[0]):\n",
    "                            if one_dict_saved_num[k] != saved_num_for_TF_mask_x[k]:\n",
    "                                sub_is_unique = True\n",
    "                                break\n",
    "                        if not sub_is_unique:\n",
    "                            is_unique = False\n",
    "                            break\n",
    "                    if is_unique:\n",
    "                        save_use[:] = False\n",
    "                        for j in range(i):\n",
    "                            if not np.all(TF[use[j]][TF_mask_x]):\n",
    "                                save_use[j] = True\n",
    "                        return_dict[n] = check_pattern[use[save_use]].copy()\n",
    "                        dict_saved_num[n] = saved_num_for_TF_mask_x.copy()\n",
    "                        n += 1\n",
    "            done_plus = update_combination(use[:i], len_check_pattern)\n",
    "            if not done_plus:\n",
    "                break\n",
    "        if n != 0:\n",
    "            return_arr = np.full((n, return_len, 2), int_nan, dtype=\"int8\")\n",
    "            for j in range(n):\n",
    "                arr = return_dict[j]\n",
    "                return_arr[j, : arr.shape[0]] = arr\n",
    "            return True, False, return_arr\n",
    "    return False, False, np.empty((0, return_len, 2), dtype=\"int8\")\n",
    "\n",
    "\n",
    "max_op = 7\n",
    "num_threads = 3\n",
    "random_x = np.random.random((8, 30))\n",
    "check_exist_eq = np.array([[1, 2, 3, -2, -4, 1, -2, 1, 4, 5, -2, -4, -1 ,6, -3],\n",
    "                           [1, 2, 3, -2, -4, 1, -1, 1, 4, 5, -2, -4, -1 ,6, -3],\n",
    "                           [1, 2, 3, -2, -4, 1, -2, 1, 4, 5, -2, -4, -2 ,6, -3],])\n",
    "dict_mask_x = make_dict_mask_x(max_op + 1)\n",
    "indexes = np.array([0, 1, 2])\n",
    "dict_before_check_change_x1 = {0 : np.array([[2, 3], [4, 5], [2, 4]]),\n",
    "                               1 : np.array([[2, 3], [4, 5], [2, 4]]),\n",
    "                               2 : np.array([[2, 3], [4, 5]])}\n",
    "dict_changed_before_check_change_x2 = {0 : np.empty((0,2), dtype=\"int64\"),\n",
    "                                       1 : np.empty((0,2), dtype=\"int64\"),\n",
    "                                       2 : np.empty((0,2), dtype=\"int64\")}\n",
    "\n",
    "sub_check_exist_step3_last(\n",
    "max_op,\n",
    "num_threads,\n",
    "random_x,\n",
    "check_exist_eq,\n",
    "dict_mask_x,\n",
    "indexes,\n",
    "dict_before_check_change_x1,\n",
    "dict_changed_before_check_change_x2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3 -2 -4  1 -2  1  4  5 -2 -4 -1]\n",
      "norm_same_for_mask_x\n",
      "[ 0  1  2  3  4  5  6  7  4  8  2  9  9 10  5 11  0  6  8 11  3 10  1  7\n",
      " 12 13 14 15 16 17 18 19 16 20 14 21 21 22 17 23 12 18 20 23 15 22 13 19\n",
      " 24 25 26 27 28 29 30 31 28 32 26 33 33 34 29 35 24 30 32 35 27 34 25 31\n",
      " 36 37 38 39 40 41 42 43 40 44 38 45 45 46 41 47 36 42 44 47 39 46 37 43\n",
      " 48 49 50 51 52 53 54 55 52 56 50 57 57 58 53 59 48 54 56 59 51 58 49 55]\n",
      "test\n",
      "0 (True, False, array([[[   2,    4],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n",
      "[ 1  2  3 -2 -4  1 -1  1  4  5 -2 -4 -1]\n",
      "norm_same_for_mask_x\n",
      "[ 7  6 10  9 11  8  1  0 11  5 10  3  3  2  8  4  7  1  5  4  9  2  6  0\n",
      " 19 18 22 21 23 20 13 12 23 17 22 15 15 14 20 16 19 13 17 16 21 14 18 12\n",
      " 31 30 34 33 35 32 25 24 35 29 34 27 27 26 32 28 31 25 29 28 33 26 30 24\n",
      " 43 42 46 45 47 44 37 36 47 41 46 39 39 38 44 40 43 37 41 40 45 38 42 36\n",
      " 55 54 58 57 59 56 49 48 59 53 58 51 51 50 56 52 55 49 53 52 57 50 54 48]\n",
      "test\n",
      "1 (True, False, array([[[   2,    4],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n",
      "[ 1  2  3 -2 -4  1 -2  1  4  5 -2 -4 -2]\n",
      "norm_same_for_mask_x\n",
      "[ 1  0  3  2  5  4  7  6  8  4  9  2 10  9 11  5  6  0 11  8 10  3  7  1\n",
      " 13 12 15 14 17 16 19 18 20 16 21 14 22 21 23 17 18 12 23 20 22 15 19 13\n",
      " 25 24 27 26 29 28 31 30 32 28 33 26 34 33 35 29 30 24 35 32 34 27 31 25\n",
      " 37 36 39 38 41 40 43 42 44 40 45 38 46 45 47 41 42 36 47 44 46 39 43 37\n",
      " 49 48 51 50 53 52 55 54 56 52 57 50 58 57 59 53 54 48 59 56 58 51 55 49]\n",
      "test\n",
      "2 (True, False, array([[[   2,    5],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   3,    4],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   4,    3],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]],\n",
      "\n",
      "       [[   5,    2],\n",
      "        [-100, -100],\n",
      "        [-100, -100],\n",
      "        [-100, -100]]], dtype=int8))\n"
     ]
    }
   ],
   "source": [
    "max_op = 6\n",
    "num_threads = 1\n",
    "random_x = np.random.random((max_op + 1, 30))\n",
    "check_exist_eq = np.array([[1, 2, 3, -2, -4, 1, -2, 1, 4, 5, -2, -4, -1],\n",
    "                           [1, 2, 3, -2, -4, 1, -1, 1, 4, 5, -2, -4, -1],\n",
    "                           [1, 2, 3, -2, -4, 1, -2, 1, 4, 5, -2, -4, -2]])\n",
    "dict_mask_x = make_dict_mask_x(max_op + 1)\n",
    "indexes = np.array([0, 1, 2])\n",
    "dict_before_check_change_x1 = {0 : np.array([[2, 3]]),\n",
    "                               1 : np.array([[2, 3]]),\n",
    "                               2 : np.array([[2, 3]])}\n",
    "dict_changed_before_check_change_x2 = {0 : np.array([[4, 5]]),\n",
    "                                       1 : np.array([[4, 5]]),\n",
    "                                       2 : np.array([[4, 5]])}\n",
    "\n",
    "sub_check_exist_step3_last(\n",
    "max_op,\n",
    "num_threads,\n",
    "random_x,\n",
    "check_exist_eq,\n",
    "dict_mask_x,\n",
    "indexes,\n",
    "dict_before_check_change_x1,\n",
    "dict_changed_before_check_change_x2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_for_make_cache import make_dict_mask_x\n",
    "max_op = 5\n",
    "#make_dict_mask_x(max_op + 1)[5]\n",
    "# [0, 1, 2, 5, 3, 4],\n",
    "# [0, 1, 3, 4, 2, 5],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
